{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Fine-tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1866927b270d47b4ad6209d0835ac20f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cd77e4907a1246bfaac4885fbc3b842a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_27c654d59b35445d9906db81a83f095d",
              "IPY_MODEL_3066b7a2b24244769da20f33cb885513",
              "IPY_MODEL_202dcd256a5b4389beb2a6da1b558ba5"
            ]
          }
        },
        "cd77e4907a1246bfaac4885fbc3b842a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27c654d59b35445d9906db81a83f095d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3abd4998b1194055ab2df373b714a6be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e74881323b7b49b2a3f3db457e2421e7"
          }
        },
        "3066b7a2b24244769da20f33cb885513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_81f63eca5b0047459cc9e18ff158b5b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_790be4ffa4134d12ab6d92e0dae12ffe"
          }
        },
        "202dcd256a5b4389beb2a6da1b558ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_692470be6356456e81d6e44d02fe8167",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 934kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f7e7abbf17d48f5b142be532aa7dd96"
          }
        },
        "3abd4998b1194055ab2df373b714a6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e74881323b7b49b2a3f3db457e2421e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81f63eca5b0047459cc9e18ff158b5b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "790be4ffa4134d12ab6d92e0dae12ffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "692470be6356456e81d6e44d02fe8167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f7e7abbf17d48f5b142be532aa7dd96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "864d3bf4da534fe5accf831af93f10bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_decc4673593040e38aebab0c1ceea095",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db4510c019be4421a0084c7505338883",
              "IPY_MODEL_4f306ed51879431ca958f7e80339b7c9",
              "IPY_MODEL_9deafc490b5c4bb992e4dcddcca37bf6"
            ]
          }
        },
        "decc4673593040e38aebab0c1ceea095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db4510c019be4421a0084c7505338883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a1d5abae5f2346b9be424bdf5e4234df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb2c387b86794e6eb322a41013756ef0"
          }
        },
        "4f306ed51879431ca958f7e80339b7c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_acee415cf4a348e39c6705b91952beba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93bf7ee69246461fa844bd5156b15afb"
          }
        },
        "9deafc490b5c4bb992e4dcddcca37bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fd94204b72694fe9b2958901f32f355c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 17.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c7230443bf249e3945ea111c41ef3c9"
          }
        },
        "a1d5abae5f2346b9be424bdf5e4234df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb2c387b86794e6eb322a41013756ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acee415cf4a348e39c6705b91952beba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93bf7ee69246461fa844bd5156b15afb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd94204b72694fe9b2958901f32f355c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c7230443bf249e3945ea111c41ef3c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55024c61f36249ba86837e5afe45e6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c72949cd5d8a4b90b20a78eee1a7e2eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_136d565bd279440bb79128e7d8da3228",
              "IPY_MODEL_167ca2b987df4e9e806e36e356b66634",
              "IPY_MODEL_4352e9a2c1b64caa96e61e87bb1eab1a"
            ]
          }
        },
        "c72949cd5d8a4b90b20a78eee1a7e2eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "136d565bd279440bb79128e7d8da3228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8491445338f84a9d8f902c9611aabe5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_145ff6bc983d405eb71fa206de679ee4"
          }
        },
        "167ca2b987df4e9e806e36e356b66634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4c154b37fd7f44da80bffc599f51b757",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19c7ad2b26e744eaac6b83620c84cce5"
          }
        },
        "4352e9a2c1b64caa96e61e87bb1eab1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_abef84d25c384110b6abeab0b466a1ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 56.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbf1d894550e42a29e78379e0f296b44"
          }
        },
        "8491445338f84a9d8f902c9611aabe5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "145ff6bc983d405eb71fa206de679ee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c154b37fd7f44da80bffc599f51b757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19c7ad2b26e744eaac6b83620c84cce5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abef84d25c384110b6abeab0b466a1ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbf1d894550e42a29e78379e0f296b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfTrB-1c_9q1",
        "outputId": "e1ca05d1-eeb4-4598-fce8-660988e65219"
      },
      "source": [
        "%%writefile requirements.txt\n",
        "nltk==3.5\n",
        "rouge==1.0.0\n",
        "matplotlib==3.3.4\n",
        "pytorch_lightning==1.2.3\n",
        "numpy==1.19.5\n",
        "razdel==0.5.0\n",
        "pymystem3==0.2.0\n",
        "torch==1.7.1\n",
        "transformers==4.3.2\n",
        "fasttext==0.9.2\n",
        "pandas==1.1.5\n",
        "tqdm==4.56.1\n",
        "allennlp==2.1.0\n",
        "beautifulsoup4==4.9.3\n",
        "scikit_learn==0.24.1\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_ymrQlHi8W1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a2fe2dd-0f0a-4667-def8-64cb28f0bde7"
      },
      "source": [
        "!pip install --upgrade -r requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nltk==3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 13.0MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 17.2MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 20.4MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 22.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 12.5MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 13.9MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71kB 10.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81kB 7.9MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 8.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102kB 9.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112kB 9.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122kB 9.1MB/s eta 0:00:01\r\u001b[K     |███                             | 133kB 9.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143kB 9.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153kB 9.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163kB 9.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 174kB 9.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 184kB 9.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 194kB 9.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 204kB 9.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 215kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 225kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 235kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 245kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 256kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 266kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 276kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 286kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 296kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 307kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 317kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 327kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 337kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 348kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 358kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 368kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 378kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 389kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 399kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 409kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 419kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 430kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 440kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 450kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 460kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 471kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 481kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 491kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 501kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 512kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 522kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 532kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 542kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 552kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 563kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 573kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 583kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 593kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 604kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 614kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 624kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 634kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 645kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 655kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 665kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 675kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 686kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 696kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 706kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 716kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 727kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 737kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 747kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 757kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 768kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 778kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 788kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 798kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 808kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 819kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 829kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 839kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 849kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 860kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 870kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 880kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 890kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 901kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 911kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 921kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 931kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 942kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 952kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 962kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 972kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 983kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 993kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.0MB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.0MB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.0MB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0MB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.0MB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1MB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1MB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.1MB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.1MB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.1MB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.2MB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2MB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.2MB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.2MB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2MB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.2MB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.3MB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.3MB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3MB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.3MB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.3MB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.3MB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.4MB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4MB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.4MB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.4MB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4MB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.4MB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.4MB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.4MB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 9.1MB/s \n",
            "\u001b[?25hCollecting rouge==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
            "Collecting matplotlib==3.3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/3d/db9a6b3c83c9511301152dbb64a029c3a4313c86eaef12c237b13ecf91d6/matplotlib-3.3.4-cp37-cp37m-manylinux1_x86_64.whl (11.5MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6MB 46.8MB/s \n",
            "\u001b[?25hCollecting pytorch_lightning==1.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/f0/3ee1bdd9d9f9d03e767d0a5aa31d582640c35ec97c940a4570da608aee5d/pytorch_lightning-1.2.3-py3-none-any.whl (821kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 46.1MB/s \n",
            "\u001b[?25hRequirement already up-to-date: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n",
            "Collecting razdel==0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/15/2c/664223a3924aa6e70479f7d37220b3a658765b9cfe760b4af7ffdc50d38f/razdel-0.5.0-py3-none-any.whl\n",
            "Requirement already up-to-date: pymystem3==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.2.0)\n",
            "Collecting torch==1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 21kB/s \n",
            "\u001b[?25hCollecting transformers==4.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 53.5MB/s \n",
            "\u001b[?25hCollecting fasttext==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.3MB/s \n",
            "\u001b[?25hRequirement already up-to-date: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.1.5)\n",
            "Collecting tqdm==4.56.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/c1/2b9a2bf4b47481777c79bf6daad23a621ffc81e15fb0edf23b8ce42e0d61/tqdm-4.56.1-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.6MB/s \n",
            "\u001b[?25hCollecting allennlp==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/bd/c75fa01e3deb9322b637fe0be45164b40d43747661aca9195b5fb334947c/allennlp-2.1.0-py3-none-any.whl (585kB)\n",
            "\u001b[K     |████████████████████████████████| 593kB 48.5MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 55.1MB/s \n",
            "\u001b[?25hCollecting scikit_learn==0.24.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r requirements.txt (line 1)) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from rouge==1.0.0->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->-r requirements.txt (line 3)) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->-r requirements.txt (line 3)) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->-r requirements.txt (line 3)) (2.8.1)\n",
            "Collecting PyYAML!=5.4.*,>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 51.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (2.4.1)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 44.9MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/a6bfee0ddf47b254286b9bd574e6f50978c69897647ae15b14230711806e/fsspec-0.8.7-py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 54.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from pymystem3==0.2.0->-r requirements.txt (line 7)) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->-r requirements.txt (line 8)) (3.7.4.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 45.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2->-r requirements.txt (line 9)) (3.7.2)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2->-r requirements.txt (line 9)) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.2->-r requirements.txt (line 9)) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2->-r requirements.txt (line 10)) (2.6.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2->-r requirements.txt (line 10)) (54.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5->-r requirements.txt (line 11)) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0->-r requirements.txt (line 13)) (8.7.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0->-r requirements.txt (line 13)) (1.4.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 47.5MB/s \n",
            "\u001b[?25hCollecting overrides==3.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Collecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 47.0MB/s \n",
            "\u001b[?25hCollecting torchvision<0.9.0,>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/df/969e69a94cff1c8911acb0688117f95e1915becc1e01c73e7960a2c76ec8/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 206kB/s \n",
            "\u001b[?25hCollecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/40/6f16e5ac994b16fa71c24310f97174ce07d3a97b433275589265c6b94d2b/jsonnet-0.17.0.tar.gz (259kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 53.0MB/s \n",
            "\u001b[?25hCollecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/1a/f2db026d4d682303793559f1c2bb425ba3ec0d6fd7ac63397790443f2461/jsonpickle-2.0.0-py2.py3-none-any.whl\n",
            "Collecting boto3<2.0,>=1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/3e/1649fa2b98a71635f721b00fd45477f7e2ecb4d5416d768abfa992ba771c/boto3-1.17.29-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 53.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0->-r requirements.txt (line 13)) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: spacy<3.1,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0->-r requirements.txt (line 13)) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0->-r requirements.txt (line 13)) (3.6.4)\n",
            "Requirement already satisfied, skipping upgrade: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0->-r requirements.txt (line 13)) (0.99)\n",
            "Collecting soupsieve>1.2; python_version >= \"3.0\"\n",
            "  Downloading https://files.pythonhosted.org/packages/41/e7/3617a4b988ed7744743fb0dbba5aa0a6e3f95a9557b43f8c4740d296b48a/soupsieve-2.2-py3-none-any.whl\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (1.27.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (0.4.3)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 45.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pymystem3==0.2.0->-r requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pymystem3==0.2.0->-r requirements.txt (line 7)) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pymystem3==0.2.0->-r requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pymystem3==0.2.0->-r requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.3.2->-r requirements.txt (line 9)) (3.4.1)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/43/4b4a1b26eb03a429a4c37ca7fdf369d938bd60018fc194e94b8379b0c77c/s3transfer-0.3.4-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.1MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.29\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/d0/b14d6bff655a0d24a2035480ac31d806844ae549c0db114acc450e4db8b8/botocore-1.20.29-py2.py3-none-any.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 47.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0->-r requirements.txt (line 13)) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0->-r requirements.txt (line 13)) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0->-r requirements.txt (line 13)) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0->-r requirements.txt (line 13)) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0->-r requirements.txt (line 13)) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0->-r requirements.txt (line 13)) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0->-r requirements.txt (line 13)) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0->-r requirements.txt (line 13)) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0->-r requirements.txt (line 13)) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0->-r requirements.txt (line 13)) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0->-r requirements.txt (line 13)) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0->-r requirements.txt (line 13)) (1.10.0)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0->-r requirements.txt (line 13)) (20.3.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (4.2.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (1.3.0)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 58.9MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.2.3->-r requirements.txt (line 4)) (3.1.0)\n",
            "Building wheels for collected packages: nltk, fasttext, PyYAML, future, sacremoses, overrides, jsonnet\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp37-none-any.whl size=1434678 sha256=a3949cdd1c1a7c0314d3d64513dd14c0330b6888f3fb7e9cbf798e7fe33c15b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3097892 sha256=d43f1f6effa61e90c26a401f34777015250136f36a70ec6609fd6529d75ae4c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44620 sha256=6874df5cf39e7c7d1f8c0f41de3111b4170b5654841caa096719408c2226999c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=2a02676f002363ecf9a9f80592dc365a6f8d3e2911869eb083ad94a3a900a3b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=52f347537eb5686f9eb5e2ea25ddf640aa9b604e979b0701af0f19ce661b1224\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp37-none-any.whl size=10174 sha256=d540050fc7ec3c7b64a01d04714f9b66dd448cfdc5d89b19a2d42ff10132b77d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.17.0-cp37-cp37m-linux_x86_64.whl size=3388787 sha256=ec46b6d1b643a6a765d2690c5649acd6d8b87f851316ed98ae078567adc8ea3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/7a/37/7dbcc30a6b4efd17b91ad1f0128b7bbf84813bd4e1cfb8c1e3\n",
            "Successfully built nltk fasttext PyYAML future sacremoses overrides jsonnet\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.20.29 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tqdm, nltk, rouge, matplotlib, torch, PyYAML, future, async-timeout, multidict, yarl, aiohttp, fsspec, pytorch-lightning, razdel, tokenizers, sacremoses, transformers, fasttext, threadpoolctl, scikit-learn, sentencepiece, overrides, tensorboardX, torchvision, jsonnet, jsonpickle, jmespath, botocore, s3transfer, boto3, allennlp, soupsieve, beautifulsoup4\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: torchvision 0.9.0+cu101\n",
            "    Uninstalling torchvision-0.9.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.0+cu101\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed PyYAML-5.3.1 aiohttp-3.7.4.post0 allennlp-2.1.0 async-timeout-3.0.1 beautifulsoup4-4.9.3 boto3-1.17.29 botocore-1.20.29 fasttext-0.9.2 fsspec-0.8.7 future-0.18.2 jmespath-0.10.0 jsonnet-0.17.0 jsonpickle-2.0.0 matplotlib-3.3.4 multidict-5.1.0 nltk-3.5 overrides-3.1.0 pytorch-lightning-1.2.3 razdel-0.5.0 rouge-1.0.0 s3transfer-0.3.4 sacremoses-0.0.43 scikit-learn-0.24.1 sentencepiece-0.1.95 soupsieve-2.2 tensorboardX-2.1 threadpoolctl-2.1.0 tokenizers-0.10.1 torch-1.7.1 torchvision-0.8.2 tqdm-4.56.1 transformers-4.3.2 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjhXEBfsDtNc",
        "outputId": "5d8e11e1-5e03-4712-a045-f407044f23e1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw_bXFBLlZ_4"
      },
      "source": [
        "def download_dataset():\n",
        "    # download\n",
        "    if \"negative.csv\" not in os.listdir() or \"positive.csv\" not in os.listdir():\n",
        "        os.system(\"wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\")\n",
        "        os.system(\"wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\")\n",
        "\n",
        "    n = ['id', 'date', 'name', 'text', 'typr', 'rep', 'rtw', 'faw', 'stcount', 'foll', 'frien', 'listcount']\n",
        "    data_positive = pd.read_csv('positive.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])\n",
        "    data_negative = pd.read_csv('negative.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])\n",
        "\n",
        "    sample_size = min(data_positive.shape[0], data_negative.shape[0])\n",
        "    raw_data = np.concatenate((data_positive['text'].values[:sample_size], data_negative['text'].values[:sample_size]),\n",
        "                              axis=0)\n",
        "    def preprocess_text(text):\n",
        "        text = text.lower().replace(\"ё\", \"е\")\n",
        "        text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', text)\n",
        "        text = re.sub('@[^\\s]+', 'USER', text)\n",
        "        text = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', text)\n",
        "        text = re.sub(' +', ' ', text)\n",
        "        return text.strip()\n",
        "\n",
        "    df_train = pd.DataFrame(columns=['text', 'label'])\n",
        "    df_test = pd.DataFrame(columns=['text', 'label'])\n",
        "\n",
        "    data = [preprocess_text(t) for t in raw_data]\n",
        "    labels = [1] * sample_size + [0] * sample_size\n",
        "    df_train['text'], df_test['text'], df_train['label'], df_test['label'] = train_test_split(data, labels,\n",
        "                                                                                              test_size=0.2,\n",
        "                                                                                              random_state=1)\n",
        "    df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=1)\n",
        "    return df_train, df_val, df_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7-hVClUmf6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a02fbd-ad70-4c53-b9a6-9302ea2348f6"
      },
      "source": [
        "import random\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "download_dataset()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                                     text  label\n",
              " 85913   раньше все встречались у фонтана в гуме а тепе...      1\n",
              " 42792   ни когда не пойму любовь женщины к женщине хот...      1\n",
              " 85556   два сеанса в кино вот что я люблю парам пам па...      1\n",
              " 36360   я нашел мой наряд для кэти перри USER URL via ...      1\n",
              " 154940          USER ууууу всеее развод обидки и все дела      1\n",
              " ...                                                   ...    ...\n",
              " 73349   закидываю свой вконтакторостер строчками из пе...      1\n",
              " 109259  гребаный понедельник гребанные 4 пары хочу дом...      0\n",
              " 50057   болячки вроде подживают но губы увеличелись в ...      0\n",
              " 5192        USER я знала что она добрая а за что она тебе      1\n",
              " 128037  USER вместо похода в кино пришлось тащиться в ...      0\n",
              " \n",
              " [143260 rows x 2 columns],\n",
              "                                                      text  label\n",
              " 9684    чем занимались если не секрет не бойся не фотк...      1\n",
              " 108504  USER я бы тоже хотел иметь немного вокальный г...      1\n",
              " 51715                   я упорот в щи d USER поймет d URL      1\n",
              " 125700  rt USER USER для лгбт флагов есть добр акции м...      0\n",
              " 81208   USER USER насчет специальности USER не в курсе...      1\n",
              " ...                                                   ...    ...\n",
              " 53243   капец я даже не знаю в чем 25 го идти мне нече...      0\n",
              " 45460   думаю уже пора отправлять новогодние подарки п...      1\n",
              " 4426           влад переходит в другую школу печаль обида      0\n",
              " 115007  rt USER привет жуйк а я пишу это со свеженьког...      1\n",
              " 67829   USER бесполезная писанина с обеих сторон каждо...      1\n",
              " \n",
              " [35816 rows x 2 columns],\n",
              "                                                     text  label\n",
              " 0        USER ну ты д читаешь мня и значит входишь в нее      1\n",
              " 1      USER даа ща побольше хвост как у енота немного...      1\n",
              " 2      USER d как ты фотки присылать каждого актера d...      1\n",
              " 3      rt USER скоро cкоро уже все начнут покупать но...      1\n",
              " 4      USER USER URL девы печальбеда ибо его возможно...      0\n",
              " ...                                                  ...    ...\n",
              " 44765  мне так нравится голос химо он ниже чем у оста...      1\n",
              " 44766  вот такие вот дела но плюсов конечно же намног...      1\n",
              " 44767  USER что то мы договаривались все вместе подар...      0\n",
              " 44768  терпеть не могу когда хочу сказать какое то сл...      0\n",
              " 44769                   USER тебя там так жестко накрыло      0\n",
              " \n",
              " [44770 rows x 2 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkShglDCnEVe"
      },
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxMyjjPxi1aX"
      },
      "source": [
        "# https://github.com/huggingface/transformers/blob/e6cff60b4cbc1158fbd6e4a1c3afda8dc224f566/examples/run_glue.py#L69\n",
        "# https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=Ykk0P9JiKtVe\n",
        "\n",
        "def train():\n",
        "    df_train, df_val, df_test = download_dataset()\n",
        "    # Load the BERT tokenizer\n",
        "    print('Loading BERT tokenizer...')\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    # get dataloaders\n",
        "    train_dataloader, validation_dataloader, test_dataloader = load_and_format(\n",
        "        df_train, df_val, df_test, tokenizer, BATCH_SIZE)\n",
        "\n",
        "    # Load BertForSequenceClassification, the pretrained BERT model with a single\n",
        "    # linear classification layer on top.\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-uncased\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
        "        num_labels=2,  # The number of output labels--2 for binary classification.\n",
        "        # You can increase this for multi-class tasks.\n",
        "        output_attentions=False,  # Whether the model returns attentions weights.\n",
        "        output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
        "    )\n",
        "    # Tell pytorch to run this model on the GPU.\n",
        "    model.cuda()\n",
        "\n",
        "    # Batch size: 16, 32\n",
        "    # Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "    # Number of epochs: 2, 3, 4\n",
        "    # Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "    optimizer = AdamW(model.parameters(),\n",
        "                      lr=2e-5,  # args.learning_rate - default is 5e-5,\n",
        "                      eps=1e-8  # args.adam_epsilon  - default is 1e-8.\n",
        "                      )\n",
        "    epochs = 4\n",
        "    # Total number of training steps is [number of batches] x [number of epochs].\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0,\n",
        "                                                num_training_steps=total_steps)\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    model, df_stats = fit_model(\n",
        "        epochs,\n",
        "        model,\n",
        "        train_dataloader,\n",
        "        validation_dataloader,\n",
        "        device,\n",
        "        optimizer,\n",
        "        scheduler\n",
        "    )\n",
        "    print(df_stats)\n",
        "    save_model(model, tokenizer, output_dir=\"fine-tuned-bert\")\n",
        "\n",
        "    # evaluate\n",
        "    predictions, true_labels = predict(model, train_dataloader, device)\n",
        "    print(\"Accuracy on train: {}\".format(flat_accuracy(predictions[0], true_labels[0])))\n",
        "    predictions, true_labels = predict(model, validation_dataloader, device)\n",
        "    print(\"Accuracy on val: {}\".format(flat_accuracy(predictions[0], true_labels[0])))\n",
        "    predictions, true_labels = predict(model, test_dataloader, device)\n",
        "    print(\"Accuracy on test: {}\".format(flat_accuracy(predictions[0], true_labels[0])))\n",
        "    return df_stats\n",
        "\n",
        "\n",
        "def fit_model(\n",
        "        epochs,\n",
        "        model,\n",
        "        train_dataloader,\n",
        "        validation_dataloader,\n",
        "        device,\n",
        "        optimizer,\n",
        "        scheduler,\n",
        "):\n",
        "    training_stats = []\n",
        "    total_t0 = time.time()\n",
        "\n",
        "    for epoch_i in range(0, epochs):\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. `dropout` and `batchnorm` layers behave differently during training vs. test\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            if step % 400 == 0 and not step == 0:\n",
        "                elapsed = time.time() - t0\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a backward pass.\n",
        "            # PyTorch doesn't do this because accumulating the gradients is \"convenient while training RNNs\".\n",
        "            model.zero_grad()\n",
        "\n",
        "            result = model(b_input_ids,\n",
        "                           token_type_ids=None,\n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "            loss = result.loss\n",
        "            logits = result.logits\n",
        "\n",
        "            # Accumulate the training loss over all of the batches\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        training_time = time.time() - t0\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables\n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "\n",
        "        for batch in validation_dataloader:\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which\n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                result = model(b_input_ids,\n",
        "                               token_type_ids=None,\n",
        "                               attention_mask=b_input_mask,\n",
        "                               labels=b_labels,\n",
        "                               return_dict=True)\n",
        "\n",
        "            # Get the loss and \"logits\" output by the model. The \"logits\" are the\n",
        "            # output values prior to applying an activation function like the\n",
        "            # softmax.\n",
        "            loss = result.loss\n",
        "            logits = result.logits\n",
        "\n",
        "            # Accumulate the validation loss.\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            # Calculate the accuracy for this batch of test sentences, and\n",
        "            # accumulate it over all batches.\n",
        "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Report the final accuracy for this validation run.\n",
        "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = time.time() - t0\n",
        "\n",
        "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': avg_val_accuracy,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Training complete!\")\n",
        "    print(\"Total training took {:} (h:mm:ss)\".format(time.time() - total_t0))\n",
        "    pd.set_option('precision', 2)\n",
        "    df_stats = pd.DataFrame(data=training_stats)\n",
        "    df_stats = df_stats.set_index('epoch')\n",
        "    return model, df_stats\n",
        "\n",
        "\n",
        "def predict(model, dataloader, device):\n",
        "    predictions, true_labels = [], []\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    for batch in dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids,\n",
        "                           token_type_ids=None,\n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the\n",
        "        # output values prior to applying an activation function like the\n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        # Store predictions and true labels\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "    return predictions, true_labels\n",
        "\n",
        "\n",
        "def save_model(model, tokenizer, output_dir):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    print(\"Saving model to %s\" % output_dir)\n",
        "    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "    model_to_save.save_pretrained(output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    # how to load afterwards\n",
        "    # model = <model_class>.from_pretrained(output_dir)\n",
        "    # tokenizer = <tokenizer_class>.from_pretrained(output_dir)\n",
        "    # if device is not None:\n",
        "    #     model.to(device)\n",
        "\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "\n",
        "def get_dataloader(sentences, labels, tokenizer, batch_size):\n",
        "    input_ids, attention_masks = transform_input(sentences, tokenizer)\n",
        "    labels = torch.tensor(labels)\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    dataloader = DataLoader(\n",
        "        dataset,  # The training samples.\n",
        "        sampler=RandomSampler(dataset),  # Select batches randomly\n",
        "        batch_size=batch_size  # Trains with this batch size.\n",
        "    )\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "def load_and_format(df_train, df_val, df_test, tokenizer, batch_size):\n",
        "    train_dataloader = get_dataloader(sentences=df_train[\"text\"].tolist(),\n",
        "                                      labels=df_train[\"label\"].tolist(),\n",
        "                                      tokenizer=tokenizer,\n",
        "                                      batch_size=batch_size\n",
        "                                      )\n",
        "    validation_dataloader = get_dataloader(sentences=df_val[\"text\"].tolist(),\n",
        "                                      labels=df_val[\"label\"].tolist(),\n",
        "                                      tokenizer=tokenizer,\n",
        "                                      batch_size=batch_size\n",
        "                                      )\n",
        "    test_dataloader = get_dataloader(sentences=df_test[\"text\"].tolist(),\n",
        "                                      labels=df_test[\"label\"].tolist(),\n",
        "                                      tokenizer=tokenizer,\n",
        "                                      batch_size=batch_size\n",
        "                                     )\n",
        "    return train_dataloader, validation_dataloader, test_dataloader\n",
        "\n",
        "\n",
        "def transform_input(sentences, tokenizer):\n",
        "    # Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "        # `encode_plus` will:\n",
        "        #   (1) Tokenize the sentence.\n",
        "        #   (2) Prepend the `[CLS]` token to the start.\n",
        "        #   (3) Append the `[SEP]` token to the end.\n",
        "        #   (4) Map tokens to their IDs.\n",
        "        #   (5) Pad or truncate the sentence to `max_length`\n",
        "        #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            sent,  # Sentence to encode.\n",
        "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
        "            max_length=122,  # Pad & truncate all sentences.\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,  # Construct attn. masks.\n",
        "            return_tensors='pt',  # Return pytorch tensors.\n",
        "        )\n",
        "        # Add the encoded sentence to the list.\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "\n",
        "def find_optimal_max_sentence_len(sentences, tokenizer):\n",
        "    \"\"\"\n",
        "    Training time depends on max seq len so it should be selected carefully.\n",
        "    \"\"\"\n",
        "    max_len = []\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "        # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "        input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "        # Update the maximum sentence length.\n",
        "        max_len.append(len(input_ids))\n",
        "    max_len = np.array(max_len)\n",
        "    print('Max sentence length: ', np.max(max_len))\n",
        "    print('95% sentence length: ', np.quantile(max_len, 0.95))\n",
        "    print('99% sentence length: ', np.quantile(max_len, 0.99))\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Results in:\n",
        "    Accuracy on train: 0.7959583973195589\n",
        "    Accuracy on val: 0.7422660263569354\n",
        "    Accuracy on test: 0.7386642841188296\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    seed_val = 42\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    df_stats = train()\n",
        "    return df_stats\n",
        "\n",
        "\n",
        "def eda_dataset_bert():\n",
        "    df_train, df_val, df_test = download_dataset()\n",
        "    sentences = df_train[\"text\"].tolist()\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "    find_optimal_max_sentence_len(sentences, tokenizer)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKSuqox2i6aj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1866927b270d47b4ad6209d0835ac20f",
            "cd77e4907a1246bfaac4885fbc3b842a",
            "27c654d59b35445d9906db81a83f095d",
            "3066b7a2b24244769da20f33cb885513",
            "202dcd256a5b4389beb2a6da1b558ba5",
            "3abd4998b1194055ab2df373b714a6be",
            "e74881323b7b49b2a3f3db457e2421e7",
            "81f63eca5b0047459cc9e18ff158b5b4",
            "790be4ffa4134d12ab6d92e0dae12ffe",
            "692470be6356456e81d6e44d02fe8167",
            "0f7e7abbf17d48f5b142be532aa7dd96",
            "864d3bf4da534fe5accf831af93f10bb",
            "decc4673593040e38aebab0c1ceea095",
            "db4510c019be4421a0084c7505338883",
            "4f306ed51879431ca958f7e80339b7c9",
            "9deafc490b5c4bb992e4dcddcca37bf6",
            "a1d5abae5f2346b9be424bdf5e4234df",
            "bb2c387b86794e6eb322a41013756ef0",
            "acee415cf4a348e39c6705b91952beba",
            "93bf7ee69246461fa844bd5156b15afb",
            "fd94204b72694fe9b2958901f32f355c",
            "1c7230443bf249e3945ea111c41ef3c9",
            "55024c61f36249ba86837e5afe45e6e2",
            "c72949cd5d8a4b90b20a78eee1a7e2eb",
            "136d565bd279440bb79128e7d8da3228",
            "167ca2b987df4e9e806e36e356b66634",
            "4352e9a2c1b64caa96e61e87bb1eab1a",
            "8491445338f84a9d8f902c9611aabe5e",
            "145ff6bc983d405eb71fa206de679ee4",
            "4c154b37fd7f44da80bffc599f51b757",
            "19c7ad2b26e744eaac6b83620c84cce5",
            "abef84d25c384110b6abeab0b466a1ab",
            "dbf1d894550e42a29e78379e0f296b44"
          ]
        },
        "outputId": "669028dd-2ede-42db-80e3-43d72cf65d68"
      },
      "source": [
        "df_stats = main()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1866927b270d47b4ad6209d0835ac20f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "864d3bf4da534fe5accf831af93f10bb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55024c61f36249ba86837e5afe45e6e2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch   400  of  4,477.    Elapsed: 271.98864579200745.\n",
            "  Batch   800  of  4,477.    Elapsed: 550.7418239116669.\n",
            "  Batch 1,200  of  4,477.    Elapsed: 829.487872838974.\n",
            "  Batch 1,600  of  4,477.    Elapsed: 1108.3276586532593.\n",
            "  Batch 2,000  of  4,477.    Elapsed: 1387.5128889083862.\n",
            "  Batch 2,400  of  4,477.    Elapsed: 1666.1976428031921.\n",
            "  Batch 2,800  of  4,477.    Elapsed: 1944.7674198150635.\n",
            "  Batch 3,200  of  4,477.    Elapsed: 2223.6388561725616.\n",
            "  Batch 3,600  of  4,477.    Elapsed: 2502.3847539424896.\n",
            "  Batch 4,000  of  4,477.    Elapsed: 2780.942646741867.\n",
            "  Batch 4,400  of  4,477.    Elapsed: 3059.8838608264923.\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epoch took: 3113.4115755558014\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "  Validation Loss: 0.47\n",
            "  Validation took: 273.49474906921387\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch   400  of  4,477.    Elapsed: 278.52694606781006.\n",
            "  Batch   800  of  4,477.    Elapsed: 557.2455263137817.\n",
            "  Batch 1,200  of  4,477.    Elapsed: 835.7405619621277.\n",
            "  Batch 1,600  of  4,477.    Elapsed: 1114.51576089859.\n",
            "  Batch 2,000  of  4,477.    Elapsed: 1393.594244003296.\n",
            "  Batch 2,400  of  4,477.    Elapsed: 1672.4737658500671.\n",
            "  Batch 2,800  of  4,477.    Elapsed: 1950.9159162044525.\n",
            "  Batch 3,200  of  4,477.    Elapsed: 2229.8967130184174.\n",
            "  Batch 3,600  of  4,477.    Elapsed: 2508.479549884796.\n",
            "  Batch 4,000  of  4,477.    Elapsed: 2787.345867872238.\n",
            "  Batch 4,400  of  4,477.    Elapsed: 3066.2970123291016.\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epoch took: 3119.97852063179\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation Loss: 0.44\n",
            "  Validation took: 275.98372197151184\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch   400  of  4,477.    Elapsed: 278.9618239402771.\n",
            "  Batch   800  of  4,477.    Elapsed: 557.9393928050995.\n",
            "  Batch 1,200  of  4,477.    Elapsed: 837.0829300880432.\n",
            "  Batch 1,600  of  4,477.    Elapsed: 1116.0293109416962.\n",
            "  Batch 2,000  of  4,477.    Elapsed: 1395.0598678588867.\n",
            "  Batch 2,400  of  4,477.    Elapsed: 1673.6254575252533.\n",
            "  Batch 2,800  of  4,477.    Elapsed: 1952.794427394867.\n",
            "  Batch 3,200  of  4,477.    Elapsed: 2231.8446667194366.\n",
            "  Batch 3,600  of  4,477.    Elapsed: 2510.395416498184.\n",
            "  Batch 4,000  of  4,477.    Elapsed: 2789.236250638962.\n",
            "  Batch 4,400  of  4,477.    Elapsed: 3068.4544858932495.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epoch took: 3122.2705874443054\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation Loss: 0.44\n",
            "  Validation took: 275.9271593093872\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch   400  of  4,477.    Elapsed: 278.9903287887573.\n",
            "  Batch   800  of  4,477.    Elapsed: 558.3390691280365.\n",
            "  Batch 1,200  of  4,477.    Elapsed: 837.4725091457367.\n",
            "  Batch 1,600  of  4,477.    Elapsed: 1116.5992412567139.\n",
            "  Batch 2,000  of  4,477.    Elapsed: 1395.3839039802551.\n",
            "  Batch 2,400  of  4,477.    Elapsed: 1674.044870376587.\n",
            "  Batch 2,800  of  4,477.    Elapsed: 1952.7206790447235.\n",
            "  Batch 3,200  of  4,477.    Elapsed: 2231.5015320777893.\n",
            "  Batch 3,600  of  4,477.    Elapsed: 2510.4313752651215.\n",
            "  Batch 4,000  of  4,477.    Elapsed: 2789.224195241928.\n",
            "  Batch 4,400  of  4,477.    Elapsed: 3067.940034389496.\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epoch took: 3121.6027257442474\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.44\n",
            "  Validation took: 273.06782698631287\n",
            "\n",
            "Training complete!\n",
            "Total training took 13575.739592790604 (h:mm:ss)\n",
            "       Training Loss  Valid. Loss  ...  Training Time  Validation Time\n",
            "epoch                              ...                                \n",
            "1               0.52         0.47  ...        3113.41           273.49\n",
            "2               0.45         0.44  ...        3119.98           275.98\n",
            "3               0.41         0.44  ...        3122.27           275.93\n",
            "4               0.38         0.44  ...        3121.60           273.07\n",
            "\n",
            "[4 rows x 5 columns]\n",
            "Saving model to fine-tuned-bert\n",
            "Accuracy on train: 0.90625\n",
            "Accuracy on val: 0.90625\n",
            "Accuracy on test: 0.78125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCBmF7-WnQcz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "348852ca-778c-43ac-b93b-78d0c7548d94"
      },
      "source": [
        "df_stats\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.52</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.76</td>\n",
              "      <td>3113.41</td>\n",
              "      <td>273.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.45</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.79</td>\n",
              "      <td>3119.98</td>\n",
              "      <td>275.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.41</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.79</td>\n",
              "      <td>3122.27</td>\n",
              "      <td>275.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.38</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.80</td>\n",
              "      <td>3121.60</td>\n",
              "      <td>273.07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  ...  Training Time  Validation Time\n",
              "epoch                              ...                                \n",
              "1               0.52         0.47  ...        3113.41           273.49\n",
              "2               0.45         0.44  ...        3119.98           275.98\n",
              "3               0.41         0.44  ...        3122.27           275.93\n",
              "4               0.38         0.44  ...        3121.60           273.07\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0gebHM7Dc04"
      },
      "source": [
        "!cp -r /content/fine-tuned-bert /content/gdrive/MyDrive/NLP/fine-tuned-bert"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CP8lU5wIkR_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}