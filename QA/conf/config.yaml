model_name: "meta-llama/Llama-2-7b-hf"
dataset_type: "decoder"
bnb_config:
  load_in_4_bit: True
  bnb_4bit_use_double_quant: True
  bnb_4bit_quant_type: "nf4"
lora_config:
  lora_target_modules: None
  lora_rank: 16
  lora_alpha: 64
  lora_dropout: 0.1
  lora_bias: "none"
  lora_task_type: "CAUSAL_LM"
training_args:
  max_memory: "15000MB"
  batch_size: 2
  learning_rate: 1e-5
  log_every_steps: 50
  seed: 42
  max_length: 2048
  matmul_precision: "high" # "high", "highest", "medium"
  device: "cuda"
  device_num: "auto" # "auto" or number of gpu
  log_path: "model"
  save_path: "model_vals"
  epochs: 5
  gradient_accumulation_steps: 16
  saving_checkpoint_monitor: "val/loss"
  saving_checkpoint_mode: "min"
  early_stopper:
    use_early_stopper: True
    patience: 3
    monitor: "val/loss"
    early_stop_min_delta: 0.001
    early_stop_mode: "min"