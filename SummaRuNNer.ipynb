{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "embedded-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-proceeding",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "earlier-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/ria/'\n",
    "files = os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "embedded-gravity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples:  971144\n",
      "Total errors in train:  207\n",
      "Total test samples:  19825\n",
      "Total errors in train:  4\n"
     ]
    }
   ],
   "source": [
    "oracle_summary_errors = 0\n",
    "all_train_data = []\n",
    "train_files = [file for file in files if 'ria_train' in file]\n",
    "for file in train_files:\n",
    "    for line in open(folder + file, 'rb'):\n",
    "        obj = json.loads(line)\n",
    "        if obj['oracle_sentences'] == list():\n",
    "            oracle_summary_errors = oracle_summary_errors + 1\n",
    "        else:\n",
    "            all_train_data.append(obj)\n",
    "print(\"Total train samples: \", len(all_train_data))\n",
    "print(\"Total errors in train: \", oracle_summary_errors)\n",
    "\n",
    "oracle_summary_errors = 0\n",
    "all_test_data = []\n",
    "test_files = [file for file in files if 'ria_test' in file]\n",
    "for file in test_files:\n",
    "    for line in open(folder + file, 'rb'):\n",
    "        obj = json.loads(line)\n",
    "        if obj['oracle_sentences'] == list():\n",
    "            oracle_summary_errors = oracle_summary_errors + 1\n",
    "        else:\n",
    "            all_test_data.append(obj)\n",
    "print(\"Total test samples: \", len(all_test_data))\n",
    "print(\"Total errors in train: \", oracle_summary_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "improving-ground",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Большая часть из 33 детей, которых граждане сша пытались вывезти из гаити в организованный в доминиканской республике приют, не являются сиротами, сообщает в воскресенье агентство франс пресс со ссылкой на заявление представителя международной организации \"детские деревни sos\" (sos children\\'s village), оказывающей помощь детям, оставшимся без родителей Как заявила агентству патрисия варгас (patricia vargas), курирующая программы \"детских деревень sos\" в центральной америке, мексике и на карибах, поговорив с детьми она выяснила, что родители многих из них живы. Некоторые дети смогли назвать свои домашние адреса и номера телефонов, что дает возможность связаться с их родителями. В это воскресенье гаитянская полиция задержала десятерых граждан сша, подозреваемых в попытке без разрешения вывезти более 30 детей в доминиканскую республику. Представитель баптистской церкви в городе меридиан американского штата айдахо шон лэнкфорд (sean lankford) заявил, что задержанные прибыли на гаити в составе группы, помогающей детям, которые остались без родителей после разрушительного землетрясения 12 января. Лэнкфорд также сообщил, что в числе задержанных его дочь и жена, и они думали, что у них имеются все необходимые документы, позволяющие вывезти детей в организованный в доминиканской республике приют. В настоящее время все эти дети, за исключением маленькой девочки, страдающей от истощения, которая была госпитализирована, находятся в благотворительном центре организации в городе круа-де-букет (croix des bouquets), расположенном в 12 километрах к северо-востоку от столицы гаити порт-о-пренса. По словам варгас, точный возраст малышки не известен, врачи полагают, что ей около 7 месяцев. Центр \"детских деревень sos\" на гаити юридически не является сиротским приютом и не отдает детей на усыновление. Ранее гаитянские интернет-ресурсы сообщали, что за  детьми, оставшимися сиротами после землетрясения, охотятся педофилы и торговцы  людьми >> Как отмечает франс пресс, после разгула стихии на гаити были установлены новые правила усыновления, согласно которым премьер-министр страны жан-макс бельрив должен лично разрешить вывоз сирот. Целью подобных мер является пресечение попыток незаконного вывоза детей для преступных целей в условиях хаоса, царящего в стране после разгула стихии. По данным ответственных лиц на гаити, тысячи детей могли быть разлучены с родителями или лишиться их в результате двух землетрясений магнитудой 7 и 5,9, произошедших у побережья этого островного государства 12 января.',\n",
       " 'title': 'Большинство детей, которых пытались увезти в сша из гаити, не сироты',\n",
       " 'sentences': ['Большая часть из 33 детей, которых граждане сша пытались вывезти из гаити в организованный в доминиканской республике приют, не являются сиротами, сообщает в воскресенье агентство франс пресс со ссылкой на заявление представителя международной организации \"детские деревни sos\" (sos children\\'s village), оказывающей помощь детям, оставшимся без родителей',\n",
       "  'Как заявила агентству патрисия варгас (patricia vargas), курирующая программы \"детских деревень sos\" в центральной америке, мексике и на карибах, поговорив с детьми она выяснила, что родители многих из них живы.',\n",
       "  'Некоторые дети смогли назвать свои домашние адреса и номера телефонов, что дает возможность связаться с их родителями.',\n",
       "  'В это воскресенье гаитянская полиция задержала десятерых граждан сша, подозреваемых в попытке без разрешения вывезти более 30 детей в доминиканскую республику.',\n",
       "  'Представитель баптистской церкви в городе меридиан американского штата айдахо шон лэнкфорд (sean lankford) заявил, что задержанные прибыли на гаити в составе группы, помогающей детям, которые остались без родителей после разрушительного землетрясения 12 января.',\n",
       "  'Лэнкфорд также сообщил, что в числе задержанных его дочь и жена, и они думали, что у них имеются все необходимые документы, позволяющие вывезти детей в организованный в доминиканской республике приют.',\n",
       "  'В настоящее время все эти дети, за исключением маленькой девочки, страдающей от истощения, которая была госпитализирована, находятся в благотворительном центре организации в городе круа-де-букет (croix des bouquets), расположенном в 12 километрах к северо-востоку от столицы гаити порт-о-пренса.',\n",
       "  'По словам варгас, точный возраст малышки не известен, врачи полагают, что ей около 7 месяцев.',\n",
       "  'Центр \"детских деревень sos\" на гаити юридически не является сиротским приютом и не отдает детей на усыновление.',\n",
       "  'Ранее гаитянские интернет-ресурсы сообщали, что за  детьми, оставшимися сиротами после землетрясения, охотятся педофилы и торговцы  людьми >>',\n",
       "  'Как отмечает франс пресс, после разгула стихии на гаити были установлены новые правила усыновления, согласно которым премьер-министр страны жан-макс бельрив должен лично разрешить вывоз сирот.',\n",
       "  'Целью подобных мер является пресечение попыток незаконного вывоза детей для преступных целей в условиях хаоса, царящего в стране после разгула стихии.',\n",
       "  'По данным ответственных лиц на гаити, тысячи детей могли быть разлучены с родителями или лишиться их в результате двух землетрясений магнитудой 7 и 5,9, произошедших у побережья этого островного государства 12 января.'],\n",
       " 'oracle_sentences': [0],\n",
       " 'oracle_summary': 'Большая часть из 33 детей, которых граждане сша пытались вывезти из гаити в организованный в доминиканской республике приют, не являются сиротами, сообщает в воскресенье агентство франс пресс со ссылкой на заявление представителя международной организации \"детские деревни sos\" (sos children\\'s village), оказывающей помощь детям, оставшимся без родителей'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accessible-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# with open('all_train_data.pkl', 'wb') as f:\n",
    "#     pickle.dump(all_train_data, f)\n",
    "# with open('all_test_data.pkl', 'wb') as f:\n",
    "#     pickle.dump(all_test_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-insertion",
   "metadata": {},
   "source": [
    "### Baseline approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-native",
   "metadata": {},
   "source": [
    "BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "structured-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece import SentencePieceTrainer\n",
    "\n",
    "def train_bpe(records, model_path, model_type=\"bpe\", vocab_size=15000, lower=True):\n",
    "    temp_file_name = \"temp.txt\"\n",
    "    with open(temp_file_name, \"wb\") as temp:\n",
    "        for record in records:\n",
    "            summary = record[\"title\"].strip()\n",
    "            text = record[\"text\"].strip()\n",
    "            if lower:\n",
    "                summary = summary.lower()\n",
    "                text = text.lower()\n",
    "            if not text or not summary:\n",
    "                continue\n",
    "            temp.write((text + \"\\n\").encode('utf8'))\n",
    "            temp.write((summary + \"\\n\").encode('utf8'))\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    cmd = \"--input={} --model_prefix={} --vocab_size={} --model_type={}\".format(\n",
    "        temp_file_name,\n",
    "        os.path.join(model_path, model_type),\n",
    "        vocab_size,\n",
    "        model_type)\n",
    "    SentencePieceTrainer.Train(cmd)\n",
    "\n",
    "\n",
    "train_bpe(all_train_data, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bored-terry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>\t0\n",
      "<s>\t0\n",
      "</s>\t0\n",
      "�����\t-0\n",
      "�����\t-1\n",
      "�����\t-2\n",
      "����\t-3\n",
      "����\t-4\n",
      "����\t-5\n",
      "����\t-6\n",
      "15000\n"
     ]
    }
   ],
   "source": [
    "!head bpe.vocab\n",
    "!cat bpe.vocab | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interesting-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece import SentencePieceProcessor\n",
    "\n",
    "def bpe_tokenize(text, bpe_processor):\n",
    "    return bpe_processor.EncodeAsPieces(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "instructional-complex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁октябрь', '▁бога', 'т', '▁на', '▁изменения']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_processor = SentencePieceProcessor()\n",
    "bpe_processor.Load(\"bpe.model\")\n",
    "bpe_tokenize(\"октябрь богат на изменения\", bpe_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-shannon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "manual-laptop",
   "metadata": {},
   "source": [
    "Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "governmental-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.index2word = list()\n",
    "        self.word2index = dict()\n",
    "        self.word2count = Counter()\n",
    "        self.reset()\n",
    "\n",
    "    def get_pad(self):\n",
    "        return self.word2index[\"<pad>\"]\n",
    "\n",
    "    def get_sos(self):\n",
    "        return self.word2index[\"<sos>\"]\n",
    "\n",
    "    def get_eos(self):\n",
    "        return self.word2index[\"<eos>\"]\n",
    "\n",
    "    def get_unk(self):\n",
    "        return self.word2index[\"<unk>\"]\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = len(self.index2word)\n",
    "            self.word2count[word] += 1\n",
    "            self.index2word.append(word)\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def has_word(self, word) -> bool:\n",
    "        return word in self.word2index\n",
    "\n",
    "    def get_index(self, word):\n",
    "        if word in self.word2index:\n",
    "            return self.word2index[word]\n",
    "        return self.get_unk()\n",
    "\n",
    "    def get_word(self, index):\n",
    "        return self.index2word[index]\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.index2word)\n",
    "\n",
    "    def is_empty(self):\n",
    "        empty_size = 4\n",
    "        return self.size() <= empty_size\n",
    "\n",
    "    def shrink(self, n):\n",
    "        best_words = self.word2count.most_common(n)\n",
    "        self.reset()\n",
    "        for word, count in best_words:\n",
    "            self.add_word(word)\n",
    "            self.word2count[word] = count\n",
    "\n",
    "    def reset(self):\n",
    "        self.word2count = Counter()\n",
    "        self.index2word = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
    "        self.word2index = {word: index for index, word in enumerate(self.index2word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ambient-offer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 18168256), ('.', 12392015), ('▁в', 12005340), ('▁и', 6432972), ('▁на', 5083617), ('▁\"', 4875722), ('▁по', 3275392), ('-', 2961503), ('▁с', 2843450), ('▁-', 2309866), ('▁что', 2242613), ('▁не', 2242492), ('\"', 2035120), ('\",', 1895808), ('▁—', 1601830), ('▁из', 1334102), ('▁за', 1267384), ('▁(', 1232091), ('▁о', 1196322), ('▁а', 1104326), ('▁к', 1071177), ('▁от', 932615), ('▁для', 927934), ('▁года', 917722), ('▁до', 901930), ('▁у', 825459), ('▁', 812073), ('▁как', 808692), ('\".', 799409), (')', 789735), ('ли', 783181), ('л', 773223), ('▁при', 772246), ('на', 740021), ('▁он', 722335), ('м', 708348), ('ла', 702955), ('▁его', 701044), ('но', 692294), ('т', 680721), ('▁россии', 659036), ('ной', 646428), ('ка', 644309), (':', 638636), ('▁это', 633273), ('в', 628126), ('▁также', 622859), ('ть', 610929), (').', 606723), ('ных', 606187), ('ми', 600581), ('х', 597765), ('ного', 593355), ('▁но', 580468), ('▁во', 567119), ('та', 562942), ('я', 555759), ('с', 555366), ('▁будет', 551564), ('ный', 545331), ('▁году', 542184), ('▁рф', 539538), ('ные', 507920), ('▁со', 501707), ('н', 499731), ('▁новости', 485367), ('к', 484568), ('не', 478899), ('▁сказал', 470078), ('р', 466950), ('за', 464409), ('ки', 462642), ('▁все', 455770), ('у', 455088), ('▁риа', 438295), ('ны', 438053), ('ра', 433364), ('ма', 422008), ('ло', 420284), ('▁после', 416304), ('ная', 412599), ('▁время', 412079), ('да', 411750), ('▁под', 407661), ('▁то', 406916), ('ку', 399141), ('ным', 395102), ('▁мы', 394504), ('ном', 392886), ('▁был', 391776), ('д', 391118), ('ное', 386908), ('▁более', 376428), ('о', 371264), ('ле', 369217), ('▁которые', 368841), ('ский', 365843), ('ю', 364828), ('е', 361394), ('▁том', 361216)]\n"
     ]
    }
   ],
   "source": [
    "def build_vocabulary(records, bpe_processor, lower=True): \n",
    "    vocabulary = Vocabulary()\n",
    "    for record in records:\n",
    "        text = record[\"text\"]\n",
    "        text = text.lower() if lower else text\n",
    "        tokens = bpe_tokenize(text, bpe_processor)\n",
    "        for token in tokens:\n",
    "            vocabulary.add_word(token)\n",
    "    return vocabulary\n",
    "\n",
    "vocabulary = build_vocabulary(all_train_data, bpe_processor)\n",
    "print(vocabulary.word2count.most_common(100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-arrest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "infinite-piece",
   "metadata": {},
   "source": [
    "Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ancient-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('bpe_processor.pkl', 'wb') as f:\n",
    "#     pickle.dump(bpe_processor, f)\n",
    "# with open('vocabulary.pkl', 'wb') as f:\n",
    "#     pickle.dump(vocabulary, f)\n",
    "with open('bpe_processor.pkl', 'rb') as f:\n",
    "    bpe_processor = pickle.load(f)\n",
    "with open('vocabulary.pkl', 'rb') as f:\n",
    "    vocabulary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "former-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import razdel\n",
    "import torch\n",
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "\n",
    "\n",
    "class BatchIterator():\n",
    "    def __init__(self, records, vocabulary, batch_size, bpe_processor, shuffle=True, lower=True, max_sentences=30, max_sentence_length=50, device=torch.device('cpu')):\n",
    "        self.records = records\n",
    "        self.num_samples = len(records)\n",
    "        self.batch_size = batch_size\n",
    "        self.bpe_processor = bpe_processor\n",
    "        self.shuffle = shuffle\n",
    "        self.batches_count = int(math.ceil(self.num_samples / batch_size))\n",
    "        self.lower = lower\n",
    "        self.rouge = Rouge()\n",
    "        self.vocabulary = vocabulary\n",
    "        self.max_sentences = max_sentences\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.batches_count\n",
    "    \n",
    "    def __iter__(self):\n",
    "        indices = np.arange(self.num_samples)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "        for start in range(0, self.num_samples, self.batch_size):\n",
    "            end = min(start + self.batch_size, self.num_samples)\n",
    "            batch_indices = indices[start:end]\n",
    "            batch_inputs = []\n",
    "            batch_outputs = []\n",
    "            max_sentence_length = 0\n",
    "            max_sentences = 0\n",
    "            batch_records = []\n",
    "            # свой max_sentences для батча\n",
    "            for data_ind in batch_indices:\n",
    "                record = self.records[data_ind]\n",
    "                batch_records.append(record)\n",
    "                text = record[\"text\"]\n",
    "                summary = record[\"title\"]\n",
    "                summary = summary.lower() if self.lower else summary\n",
    "\n",
    "                if \"sentences\" not in record:\n",
    "                    sentences = [sentence.text.lower() if self.lower else sentence.text for sentence in razdel.sentenize(text)][:self.max_sentences]\n",
    "                else:\n",
    "                    sentences = record[\"sentences\"]\n",
    "                max_sentences = max(len(sentences), max_sentences)\n",
    "\n",
    "                if \"oracle_sentences\" not in record:\n",
    "                    calc_score = lambda x, y: calc_single_score(x, y, self.rouge)\n",
    "                    sentences_indicies = build_oracle_summary_greedy(text, summary, calc_score=calc_score, lower=self.lower, max_sentences=self.max_sentences)[1]\n",
    "                else:\n",
    "                    sentences_indicies = record[\"oracle_sentences\"]\n",
    "                # len(sentences)\n",
    "                inputs = [list(map(self.vocabulary.get_index, bpe_tokenize(sentence, self.bpe_processor)[:self.max_sentence_length])) for sentence in sentences]\n",
    "                max_sentence_length = max(max_sentence_length, max([len(tokens) for tokens in inputs]))\n",
    "                # len(sentences)\n",
    "                outputs = [int(i in sentences_indicies) for i in range(len(sentences))]\n",
    "                batch_inputs.append(inputs)\n",
    "                batch_outputs.append(outputs)\n",
    "            tensor_inputs = torch.zeros((self.batch_size, max_sentences, max_sentence_length), dtype=torch.long, device=self.device)\n",
    "            tensor_outputs = torch.zeros((self.batch_size, max_sentences), dtype=torch.float32, device=self.device)\n",
    "            for i, inputs in enumerate(batch_inputs):\n",
    "                for j, sentence_tokens in enumerate(inputs):\n",
    "                    tensor_inputs[i][j][:len(sentence_tokens)] = torch.LongTensor(sentence_tokens)\n",
    "            for i, outputs in enumerate(batch_outputs):\n",
    "                tensor_outputs[i][:len(outputs)] = torch.LongTensor(outputs)\n",
    "\n",
    "            yield {\n",
    "                'inputs': tensor_inputs,\n",
    "                'outputs': tensor_outputs,\n",
    "                'records': batch_records\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "incorporated-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = BatchIterator(all_train_data, vocabulary, 4, bpe_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "complicated-registrar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs': tensor([[[   27,     3,   208,  ...,   441,  9717,   181],\n",
      "         [   27,     3,  6237,  ...,     0,     0,     0],\n",
      "         [   27,     3, 11353,  ...,     0,     0,     0],\n",
      "         ...,\n",
      "         [   27,     3,    23,  ...,     0,     0,     0],\n",
      "         [   27,     3,  1535,  ...,     0,     0,     0],\n",
      "         [   27,     3,  1384,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[   27,     3,   208,  ...,     0,     0,     0],\n",
      "         [   27,     3,   208,  ...,     0,     0,     0],\n",
      "         [  109,   820,  1231,  ...,  3994,  7337,   546],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[   27,     3,  1165,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[   27,     3,   181,  ..., 10386,   483,    41],\n",
      "         [   27,     3,  1384,  ...,     0,     0,     0],\n",
      "         [   27,     3,  1147,  ...,     0,     0,     0],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0]]]), 'outputs': tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'records': [{'text': 'Федеральная служба рф по контролю за оборотом наркотиков опровергла распространенную в ряде сми информацию о том, что сын сотрудника свр полковника щербакова, будучи работником фскн, якобы покинул россию, улетев в америку незадолго до разоблачения в сша в июне этого года группы российских агентов. Группа российских граждан была задержана в сша по подозрению в незаконной работе на рф. В июле их обменяли в венском аэропорту на четверых других россиян, осужденных ранее в рф за шпионаж и выданных теперь западу. В четверг газета \"коммерсант\" сообщила, что виновником шпионского скандала якобы стал некий полковник щербаков, долгое время служивший в службе внешней разведки (свр) россии начальником американского отдела управления \"с\", занимающегося работой с нелегалами. Щербаков, по данным издания, скрылся из россии за три дня до июньского визита президента рф дмитрия медведева в сша. Его сын, якобы трудившийся в другом ведомстве - госнаркоконтроле, также улетел в сша незадолго до скандала с агентами. \"управление по взаимодействию с общественностью и сми фскн россии официально заявляет, что в органах наркоконтроля ни среди уволенных, ни среди действующих сотрудников нет ни одного щербакова, отец которого служил бы в свр россии. Вызывает сожаление, что журналисты уважаемого издания при подготовке публикации использовали непроверенную информацию\", - говорится в заявлении, поступившем в четверг в распоряжение риа новости. По данным \"коммерсанта\", предателя не разоблачили, потому что в свр  не учли, что \"дочь щербакова давно живет в сша\". Сотрудники свр ничего  не заподозрили, даже когда щербаков отказался от повышения по службе,  предлагавшегося ему примерно за год до шпионского скандала, писало  издание. Оно указывало, что это было сделано, чтобы избежать необходимой в  таких случаях процедуры проверки на детекторе лжи. Масштабное расследование, начавшееся сразу после провала свр, не  закончилось по сей день, отметила газета. По словам источника  \"коммерсанта\", \"по делу проходит уйма бывших и действующих сотрудников  свр\".', 'title': 'Сын сотрудника свр щербакова не работает в фскн, заявили в ведомстве', 'sentences': ['Федеральная служба рф по контролю за оборотом наркотиков опровергла распространенную в ряде сми информацию о том, что сын сотрудника свр полковника щербакова, будучи работником фскн, якобы покинул россию, улетев в америку незадолго до разоблачения в сша в июне этого года группы российских агентов.', 'Группа российских граждан была задержана в сша по подозрению в незаконной работе на рф.', 'В июле их обменяли в венском аэропорту на четверых других россиян, осужденных ранее в рф за шпионаж и выданных теперь западу.', 'В четверг газета \"коммерсант\" сообщила, что виновником шпионского скандала якобы стал некий полковник щербаков, долгое время служивший в службе внешней разведки (свр) россии начальником американского отдела управления \"с\", занимающегося работой с нелегалами.', 'Щербаков, по данным издания, скрылся из россии за три дня до июньского визита президента рф дмитрия медведева в сша.', 'Его сын, якобы трудившийся в другом ведомстве - госнаркоконтроле, также улетел в сша незадолго до скандала с агентами.', '\"управление по взаимодействию с общественностью и сми фскн россии официально заявляет, что в органах наркоконтроля ни среди уволенных, ни среди действующих сотрудников нет ни одного щербакова, отец которого служил бы в свр россии.', 'Вызывает сожаление, что журналисты уважаемого издания при подготовке публикации использовали непроверенную информацию\", - говорится в заявлении, поступившем в четверг в распоряжение риа новости.', 'По данным \"коммерсанта\", предателя не разоблачили, потому что в свр  не учли, что \"дочь щербакова давно живет в сша\".', 'Сотрудники свр ничего  не заподозрили, даже когда щербаков отказался от повышения по службе,  предлагавшегося ему примерно за год до шпионского скандала, писало  издание.', 'Оно указывало, что это было сделано, чтобы избежать необходимой в  таких случаях процедуры проверки на детекторе лжи.', 'Масштабное расследование, начавшееся сразу после провала свр, не  закончилось по сей день, отметила газета.', 'По словам источника  \"коммерсанта\", \"по делу проходит уйма бывших и действующих сотрудников  свр\".'], 'oracle_sentences': [0], 'oracle_summary': 'Федеральная служба рф по контролю за оборотом наркотиков опровергла распространенную в ряде сми информацию о том, что сын сотрудника свр полковника щербакова, будучи работником фскн, якобы покинул россию, улетев в америку незадолго до разоблачения в сша в июне этого года группы российских агентов.'}, {'text': 'Рекордное за последние десять лет число людей — свыше миллиона — пересекло государственную границу россии в сочи в июле, сообщает пограничное управление фсб россии по краснодарскому краю. Летом поток людей, желающих посетить абхазию, традиционно возрастает, и на многостороннем автомобильном пункте пропуска в адлере отмечаются нагрузки, превышающие пропускную способность границы. \"такой наплыв фиксируют впервые за последние 10 лет. уже сейчас в пиковые дни ежесуточно на паспортном контроле на выезд за рубеж и въезд в российскую федерацию оформляется до 40 тысяч человек и свыше 4,5 тысячи транспортных средств. Это почти на 45% превышает пропускную способность многостороннего автомобильного пункта пропуска \"адлер\" по пассажирам и втрое — по транспорту\", — говорится в сообщении. При этом поток пересекающих границу неуклонно растет и, по прогнозам специалистов, к середине августа может превысить прошлогодний максимум в 45 тысяч граждан в сутки. В прошлом году за весь летний сезон границу пересекли 4 миллиона человек. Чтобы справиться с наплывом туристов и сократить очереди, выстраивающиеся перед пунктом пропуска в сочи, вахтовым методом уже направлены дополнительные сотрудники из других подразделений пограничного контроля. Они помогут обеспечить бесперебойную работу пункта пропуска. Для комфортного пересечения границы туристическими автобусами и легковым транспортом дополнительно организовано реверсивное движение.', 'title': 'Рекордное число людей пересекло госграницу рф в сочи', 'sentences': ['Рекордное за последние десять лет число людей — свыше миллиона — пересекло государственную границу россии в сочи в июле, сообщает пограничное управление фсб россии по краснодарскому краю.', 'Летом поток людей, желающих посетить абхазию, традиционно возрастает, и на многостороннем автомобильном пункте пропуска в адлере отмечаются нагрузки, превышающие пропускную способность границы.', '\"такой наплыв фиксируют впервые за последние 10 лет. уже сейчас в пиковые дни ежесуточно на паспортном контроле на выезд за рубеж и въезд в российскую федерацию оформляется до 40 тысяч человек и свыше 4,5 тысячи транспортных средств.', 'Это почти на 45% превышает пропускную способность многостороннего автомобильного пункта пропуска \"адлер\" по пассажирам и втрое — по транспорту\", — говорится в сообщении.', 'При этом поток пересекающих границу неуклонно растет и, по прогнозам специалистов, к середине августа может превысить прошлогодний максимум в 45 тысяч граждан в сутки.', 'В прошлом году за весь летний сезон границу пересекли 4 миллиона человек.', 'Чтобы справиться с наплывом туристов и сократить очереди, выстраивающиеся перед пунктом пропуска в сочи, вахтовым методом уже направлены дополнительные сотрудники из других подразделений пограничного контроля.', 'Они помогут обеспечить бесперебойную работу пункта пропуска.', 'Для комфортного пересечения границы туристическими автобусами и легковым транспортом дополнительно организовано реверсивное движение.'], 'oracle_sentences': [0], 'oracle_summary': 'Рекордное за последние десять лет число людей — свыше миллиона — пересекло государственную границу россии в сочи в июле, сообщает пограничное управление фсб россии по краснодарскому краю.'}, {'text': 'Стенограмма заседания', 'title': 'Опубликована стенограмма заседания экспертной группы №21', 'sentences': ['Стенограмма заседания'], 'oracle_sentences': [0], 'oracle_summary': 'Стенограмма заседания'}, {'text': 'Австрийские власти расследуют дело об ампутации здоровой ноги у 91-летней женщины в больнице города сент-йохан (земля тироль), сообщило в пятницу агентство ассошиэйтед пресс со ссылкой на местные сми. По словам представителя прокуратуры города инсбрук уилфреда шигеле (wilfried siegele), операция, в результате которой женщина лишилась обеих ног, была проведена 16 июня. Как выяснилось в ходе следствия, вместо больной ноги пациентке, имя которой не называется, ампутировали здоровую. Когда врачи поняли, что совершили ошибку, исправить что-либо было уже невозможно. Хирургам ничего не оставалось, кроме как продолжить операцию и отнять женщине вторую ногу, ампутация которой была необходима по медицинским показаниям. О случившемся руководство клиники сообщило властям, которые начали расследование. Агентству пока не удалось получить комментарии у представителей больницы.', 'title': 'Хирурги в австрии по ошибке ампутировали пациентке здоровую ногу', 'sentences': ['Австрийские власти расследуют дело об ампутации здоровой ноги у 91-летней женщины в больнице города сент-йохан (земля тироль), сообщило в пятницу агентство ассошиэйтед пресс со ссылкой на местные сми.', 'По словам представителя прокуратуры города инсбрук уилфреда шигеле (wilfried siegele), операция, в результате которой женщина лишилась обеих ног, была проведена 16 июня.', 'Как выяснилось в ходе следствия, вместо больной ноги пациентке, имя которой не называется, ампутировали здоровую.', 'Когда врачи поняли, что совершили ошибку, исправить что-либо было уже невозможно.', 'Хирургам ничего не оставалось, кроме как продолжить операцию и отнять женщине вторую ногу, ампутация которой была необходима по медицинским показаниям.', 'О случившемся руководство клиники сообщило властям, которые начали расследование.', 'Агентству пока не удалось получить комментарии у представителей больницы.'], 'oracle_sentences': [0], 'oracle_summary': 'Австрийские власти расследуют дело об ампутации здоровой ноги у 91-летней женщины в больнице города сент-йохан (земля тироль), сообщило в пятницу агентство ассошиэйтед пресс со ссылкой на местные сми.'}]}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "southwest-abortion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 13, 50])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['inputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "intense-seventh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 13])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['outputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hollywood-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "def train_model(model, train_records, val_records, vocabulary, bpe_processor, batch_size=32,\n",
    "                epochs_count=10, loss_every_nsteps=16, lr=0.001, device_name=\"cuda\"):\n",
    "    params_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Trainable params: {}\".format(params_count))\n",
    "    device = torch.device(device_name)\n",
    "    model = model.to(device)\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_function = nn.BCEWithLogitsLoss().to(device)\n",
    "    for epoch in range(epochs_count):\n",
    "        for step, batch in enumerate(BatchIterator(train_records, vocabulary, batch_size, bpe_processor, device=device)):\n",
    "            model.train()\n",
    "            logits = model(batch[\"inputs\"]) # Прямой проход\n",
    "            loss = loss_function(logits, batch[\"outputs\"]) # Подсчёт ошибки\n",
    "            loss.backward() # Подсчёт градиентов dL/dw\n",
    "            optimizer.step() # Градиентный спуск или его модификации (в данном случае Adam)\n",
    "            optimizer.zero_grad() # Зануление градиентов, чтобы их спокойно менять на следующей итерации\n",
    "            total_loss += loss.item()\n",
    "            if step % loss_every_nsteps == 0 and step != 0:\n",
    "                val_total_loss = 0\n",
    "                val_batch_count = 0\n",
    "                model.eval()\n",
    "#                 for _, val_batch in enumerate(BatchIterator(val_records, vocabulary, batch_size, bpe_processor, device=device)):\n",
    "#                     logits = model(val_batch[\"inputs\"]) # Прямой проход\n",
    "#                     val_total_loss += loss_function(logits, val_batch[\"outputs\"]) # Подсчёт ошибки\n",
    "#                     val_batch_count += 1\n",
    "#                 avg_val_loss = val_total_loss/val_batch_count\n",
    "#                 print(\"Epoch = {}, Avg Train Loss = {:.4f}, Avg val loss = {:.4f}, Time = {:.2f}s\".format(epoch, total_loss / loss_every_nsteps, avg_val_loss, time.time() - start_time))\n",
    "                print(\"Epoch = {}, Avg Train Loss = {:.4f}, Time = {:.2f}s\".format(epoch, total_loss / loss_every_nsteps, time.time() - start_time))\n",
    "                total_loss = 0\n",
    "                start_time = time.time()\n",
    "        total_loss = 0\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "automotive-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "\n",
    "class SentenceEncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3, bidirectional=True):\n",
    "        super(SentenceEncoderRNN, self).__init__()\n",
    "\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        assert hidden_size % num_directions == 0\n",
    "        hidden_size = hidden_size // num_directions\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.embedding_layer = nn.Embedding(input_size, embedding_dim)\n",
    "        self.rnn_layer = nn.LSTM(embedding_dim, hidden_size, n_layers, dropout=dropout, bidirectional=bidirectional, batch_first=True)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        embedded = self.embedding_layer(inputs)\n",
    "        outputs, _ = self.rnn_layer(embedded, hidden)\n",
    "        sentences_embeddings = torch.mean(outputs, 1)\n",
    "        return sentences_embeddings\n",
    "\n",
    "class SentenceTaggerRNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 token_embedding_dim=256,\n",
    "                 sentence_encoder_hidden_size=256,\n",
    "                 hidden_size=256,\n",
    "                 bidirectional=True,\n",
    "                 sentence_encoder_n_layers=2,\n",
    "                 sentence_encoder_dropout=0.3,\n",
    "                 sentence_encoder_bidirectional=True,\n",
    "                 n_layers=1,\n",
    "                 dropout=0.3):\n",
    "        super(SentenceTaggerRNN, self).__init__()\n",
    "\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        assert hidden_size % num_directions == 0\n",
    "        hidden_size = hidden_size // num_directions\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.sentence_encoder = SentenceEncoderRNN(vocabulary_size, token_embedding_dim,\n",
    "                                                   sentence_encoder_hidden_size, sentence_encoder_n_layers, \n",
    "                                                   sentence_encoder_dropout, sentence_encoder_bidirectional)\n",
    "        self.rnn_layer = nn.LSTM(sentence_encoder_hidden_size, hidden_size, n_layers, dropout=dropout,\n",
    "                           bidirectional=bidirectional, batch_first=True)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        self.content_linear_layer = nn.Linear(hidden_size * 2, 1)\n",
    "        self.document_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.salience_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.tanh_layer = nn.Tanh()\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        batch_size = inputs.size(0)\n",
    "        sentences_count = inputs.size(1)\n",
    "        tokens_count = inputs.size(2)\n",
    "        inputs = inputs.reshape(-1, tokens_count)\n",
    "        embedded_sentences = self.sentence_encoder(inputs)\n",
    "        embedded_sentences = embedded_sentences.reshape(batch_size, sentences_count, -1)\n",
    "        outputs, _ = self.rnn_layer(embedded_sentences, hidden)\n",
    "        outputs = self.dropout_layer(outputs)\n",
    "        document_embedding = self.tanh_layer(self.document_linear_layer(torch.mean(outputs, 1)))\n",
    "        content = self.content_linear_layer(outputs).squeeze(2)\n",
    "        salience = torch.bmm(outputs, self.salience_linear_layer(document_embedding).unsqueeze(2)).squeeze(2)\n",
    "        return content + salience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "according-purple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 5356289\n",
      "Epoch = 0, Avg Train Loss = 0.1899, Time = 4.49s\n",
      "Epoch = 0, Avg Train Loss = 0.0900, Time = 4.08s\n",
      "Epoch = 0, Avg Train Loss = 0.0862, Time = 4.16s\n",
      "Epoch = 0, Avg Train Loss = 0.0852, Time = 4.09s\n",
      "Epoch = 0, Avg Train Loss = 0.0784, Time = 3.99s\n",
      "Epoch = 0, Avg Train Loss = 0.0751, Time = 4.08s\n",
      "Epoch = 0, Avg Train Loss = 0.0758, Time = 4.25s\n",
      "Epoch = 0, Avg Train Loss = 0.0749, Time = 4.09s\n",
      "Epoch = 0, Avg Train Loss = 0.0702, Time = 4.12s\n",
      "Epoch = 0, Avg Train Loss = 0.0667, Time = 4.10s\n",
      "Epoch = 0, Avg Train Loss = 0.0739, Time = 3.96s\n",
      "Epoch = 0, Avg Train Loss = 0.0679, Time = 4.07s\n",
      "Epoch = 0, Avg Train Loss = 0.0678, Time = 4.02s\n",
      "Epoch = 0, Avg Train Loss = 0.0658, Time = 4.07s\n",
      "Epoch = 0, Avg Train Loss = 0.0662, Time = 4.19s\n",
      "Epoch = 0, Avg Train Loss = 0.0701, Time = 4.11s\n",
      "Epoch = 0, Avg Train Loss = 0.0694, Time = 4.08s\n",
      "Epoch = 0, Avg Train Loss = 0.0733, Time = 4.06s\n",
      "Epoch = 0, Avg Train Loss = 0.0662, Time = 4.16s\n",
      "Epoch = 0, Avg Train Loss = 0.0674, Time = 4.08s\n",
      "Epoch = 0, Avg Train Loss = 0.0668, Time = 4.08s\n",
      "Epoch = 0, Avg Train Loss = 0.0732, Time = 4.24s\n",
      "Epoch = 0, Avg Train Loss = 0.0713, Time = 4.07s\n",
      "Epoch = 0, Avg Train Loss = 0.0697, Time = 3.98s\n",
      "Epoch = 0, Avg Train Loss = 0.0669, Time = 4.10s\n",
      "Epoch = 0, Avg Train Loss = 0.0650, Time = 4.01s\n",
      "Epoch = 0, Avg Train Loss = 0.0728, Time = 4.14s\n",
      "Epoch = 0, Avg Train Loss = 0.0725, Time = 4.17s\n",
      "Epoch = 0, Avg Train Loss = 0.0700, Time = 4.08s\n",
      "Epoch = 0, Avg Train Loss = 0.0601, Time = 3.97s\n",
      "Epoch = 0, Avg Train Loss = 0.0683, Time = 4.03s\n",
      "Epoch = 0, Avg Train Loss = 0.0740, Time = 4.13s\n",
      "Epoch = 0, Avg Train Loss = 0.0671, Time = 3.98s\n",
      "Epoch = 0, Avg Train Loss = 0.0669, Time = 4.11s\n",
      "Epoch = 0, Avg Train Loss = 0.0620, Time = 3.96s\n",
      "Epoch = 0, Avg Train Loss = 0.0746, Time = 4.06s\n",
      "Epoch = 0, Avg Train Loss = 0.0740, Time = 4.16s\n",
      "Epoch = 0, Avg Train Loss = 0.0688, Time = 4.05s\n",
      "Epoch = 0, Avg Train Loss = 0.0732, Time = 4.12s\n",
      "Epoch = 0, Avg Train Loss = 0.0725, Time = 4.14s\n",
      "Epoch = 0, Avg Train Loss = 0.0692, Time = 4.08s\n",
      "Epoch = 0, Avg Train Loss = 0.0692, Time = 4.06s\n",
      "Epoch = 0, Avg Train Loss = 0.0722, Time = 3.91s\n",
      "Epoch = 0, Avg Train Loss = 0.0670, Time = 4.11s\n",
      "Epoch = 0, Avg Train Loss = 0.0668, Time = 4.09s\n",
      "Epoch = 0, Avg Train Loss = 0.0721, Time = 4.22s\n",
      "Epoch = 0, Avg Train Loss = 0.0670, Time = 4.06s\n",
      "Epoch = 0, Avg Train Loss = 0.0687, Time = 4.13s\n",
      "Epoch = 0, Avg Train Loss = 0.0695, Time = 4.05s\n",
      "Epoch = 0, Avg Train Loss = 0.0687, Time = 4.07s\n",
      "Epoch = 0, Avg Train Loss = 0.0662, Time = 4.22s\n",
      "Epoch = 0, Avg Train Loss = 0.0691, Time = 4.16s\n",
      "Epoch = 0, Avg Train Loss = 0.0640, Time = 4.11s\n",
      "Epoch = 0, Avg Train Loss = 0.0664, Time = 4.32s\n",
      "Epoch = 0, Avg Train Loss = 0.0680, Time = 4.25s\n",
      "Epoch = 0, Avg Train Loss = 0.0735, Time = 4.14s\n",
      "Epoch = 0, Avg Train Loss = 0.0729, Time = 4.15s\n",
      "Epoch = 0, Avg Train Loss = 0.0703, Time = 4.06s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0148e3f75665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTaggerRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_test_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpe_processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-821465259a66>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_records, val_records, vocabulary, bpe_processor, batch_size, epochs_count, loss_every_nsteps, lr, device_name)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpe_processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Прямой проход\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-86ce2ade79d3>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0msentences_indicies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"oracle_sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;31m# len(sentences)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpe_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbpe_processor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mmax_sentence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;31m# len(sentences)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-86ce2ade79d3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0msentences_indicies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"oracle_sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;31m# len(sentences)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpe_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbpe_processor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mmax_sentence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;31m# len(sentences)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-4bc8c77b0e6e>\u001b[0m in \u001b[0;36mbpe_tokenize\u001b[0;34m(text, bpe_processor)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbpe_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpe_processor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbpe_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncodeAsPieces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nlp_project/lib/python3.6/site-packages/sentencepiece/__init__.py\u001b[0m in \u001b[0;36mEncodeAsPieces\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mEncodeAsPieces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_sentencepiece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceProcessor_EncodeAsPieces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mEncodeAsIds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SentenceTaggerRNN(vocabulary.size())\n",
    "train_model(model, all_train_data, all_test_data, vocabulary, bpe_processor, device_name=\"cuda\", batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-terrorism",
   "metadata": {},
   "source": [
    "1 эпоха - примерно 16 часов на моем компьютере... Проверим так, как есть сейчас"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-eugene",
   "metadata": {},
   "source": [
    "Оценка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "celtic-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge\n",
    "\n",
    "def calc_scores(references, predictions, metric=\"all\"):\n",
    "    print(\"Count:\", len(predictions))\n",
    "    print(\"Ref:\", references[-1])\n",
    "    print(\"Hyp:\", predictions[-1])\n",
    "\n",
    "    if metric in (\"bleu\", \"all\"):\n",
    "        print(\"BLEU: \", corpus_bleu([[r] for r in references], predictions))\n",
    "    if metric in (\"rouge\", \"all\"):\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(predictions, references, avg=True)\n",
    "        print(\"ROUGE: \", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "retained-return",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 1000\n",
      "Ref: заявления жителей \"речника\" о вывозе вещей рассмотрят по закону - фссп\n",
      "Hyp: Заявления жителей поселка \"речник\" на западе москвы о предоставлении времени для вывоза имущества и строений будут рассматриваться в установленном законом порядке, сообщил в понедельник заместитель руководителя столичного управления федеральной службы судебных приставов евгений лукьянчиков.\n",
      "BLEU:  0.2023709767449148\n",
      "ROUGE:  {'rouge-1': {'f': 0.20992510106228962, 'p': 0.14500262979745654, 'r': 0.4194260128760132}, 'rouge-2': {'f': 0.09131963287817384, 'p': 0.06231760421922613, 'r': 0.18984801309801333}, 'rouge-l': {'f': 0.1988034844595074, 'p': 0.13879161888887406, 'r': 0.38346827339327355}}\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "references = []\n",
    "predictions = []\n",
    "for step, batch in enumerate(BatchIterator(all_test_data[:1000], vocabulary, 32, bpe_processor, device=device)):\n",
    "    logits = model(batch[\"inputs\"]) # Прямой проход\n",
    "    records = batch[\"records\"]\n",
    "    for record, record_logits in zip(records, logits):\n",
    "        sentences = record[\"sentences\"]\n",
    "        predicted_summary = []\n",
    "        for i, logit in enumerate(record_logits):\n",
    "            if logit > 0.0:\n",
    "                predicted_summary.append(sentences[i])\n",
    "        if not predicted_summary:\n",
    "            predicted_summary.append(sentences[torch.max(record_logits, dim=0)[1].item()])\n",
    "        predicted_summary = \" \".join(predicted_summary)\n",
    "        references.append(record[\"title\"].lower())\n",
    "        predictions.append(predicted_summary)\n",
    "\n",
    "calc_scores(references, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-broadcast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-france",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-address",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-trailer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "independent-kruger",
   "metadata": {},
   "source": [
    "### Advanced approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-graduation",
   "metadata": {},
   "source": [
    "+ +positional embeddings\n",
    "+ +bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "metropolitan-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import razdel\n",
    "import torch\n",
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "\n",
    "\n",
    "class BatchIterator():\n",
    "    def __init__(self, records, vocabulary, batch_size, bpe_processor, shuffle=True, lower=True, max_sentences=30, max_sentence_length=50, device=torch.device('cpu')):\n",
    "        self.records = records\n",
    "        self.num_samples = len(records)\n",
    "        self.batch_size = batch_size\n",
    "        self.bpe_processor = bpe_processor\n",
    "        self.shuffle = shuffle\n",
    "        self.batches_count = int(math.ceil(self.num_samples / batch_size))\n",
    "        self.lower = lower\n",
    "        self.rouge = Rouge()\n",
    "        self.vocabulary = vocabulary\n",
    "        self.max_sentences = max_sentences\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.batches_count\n",
    "    \n",
    "    def __iter__(self):\n",
    "        indices = np.arange(self.num_samples)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "        for start in range(0, self.num_samples, self.batch_size):\n",
    "            end = min(start + self.batch_size, self.num_samples)\n",
    "            batch_indices = indices[start:end]\n",
    "            batch_inputs = []\n",
    "            batch_outputs = []\n",
    "            rel_pos_inputs = []\n",
    "            max_sentence_length = 0\n",
    "            max_sentences = 0\n",
    "            batch_records = []\n",
    "            # свой max_sentences для батча\n",
    "            for data_ind in batch_indices:\n",
    "                record = self.records[data_ind]\n",
    "                batch_records.append(record)\n",
    "                text = record[\"text\"]\n",
    "                summary = record[\"title\"]\n",
    "                summary = summary.lower() if self.lower else summary\n",
    "\n",
    "                if \"sentences\" not in record:\n",
    "                    sentences = [sentence.text.lower() if self.lower else sentence.text for sentence in razdel.sentenize(text)][:self.max_sentences]\n",
    "                else:\n",
    "                    sentences = record[\"sentences\"]\n",
    "                max_sentences = max(len(sentences), max_sentences)\n",
    "\n",
    "                if \"oracle_sentences\" not in record:\n",
    "                    calc_score = lambda x, y: calc_single_score(x, y, self.rouge)\n",
    "                    sentences_indicies = build_oracle_summary_greedy(text, summary, calc_score=calc_score, lower=self.lower, max_sentences=self.max_sentences)[1]\n",
    "                else:\n",
    "                    sentences_indicies = record[\"oracle_sentences\"]\n",
    "                # len(sentences)\n",
    "                inputs = [list(map(self.vocabulary.get_index, bpe_tokenize(sentence, self.bpe_processor)[:self.max_sentence_length])) for sentence in sentences]\n",
    "                max_sentence_length = max(max_sentence_length, max([len(tokens) for tokens in inputs]))\n",
    "                # len(sentences)\n",
    "                outputs = [int(i in sentences_indicies) for i in range(len(sentences))]\n",
    "                # rel_pos\n",
    "                pos = [i / len(sentences) for i in range(len(sentences))]\n",
    "                bins = np.array([0.25, 0.5, 0.75, 1.0])\n",
    "                # possible options array([1, 2, 3, 4, 5])\n",
    "                rel_pos_inds = np.digitize(np.array([p for p in pos]), bins) + 1\n",
    "                rel_pos_inputs.append(rel_pos_inds)\n",
    "                batch_inputs.append(inputs)\n",
    "                batch_outputs.append(outputs)\n",
    "            tensor_inputs = torch.zeros((self.batch_size, max_sentences, max_sentence_length), dtype=torch.long, device=self.device)\n",
    "            tensor_outputs = torch.zeros((self.batch_size, max_sentences), dtype=torch.float32, device=self.device)\n",
    "            tensor_abs_pos = torch.zeros((self.batch_size, max_sentences), dtype=torch.long, device=self.device)\n",
    "            tensor_rel_pos = torch.zeros((self.batch_size, max_sentences), dtype=torch.long, device=self.device)\n",
    "            for i, inputs in enumerate(batch_inputs):\n",
    "                for j, sentence_tokens in enumerate(inputs):\n",
    "                    tensor_inputs[i][j][:len(sentence_tokens)] = torch.LongTensor(sentence_tokens)\n",
    "            for i, outputs in enumerate(batch_outputs):\n",
    "                tensor_outputs[i][:len(outputs)] = torch.LongTensor(outputs)\n",
    "                # abs pos\n",
    "                tensor_abs_pos[i] = torch.LongTensor([i for i in range(max_sentences)])\n",
    "            # rel pos\n",
    "            for i, rel_pos_input in enumerate(rel_pos_inputs):\n",
    "                tensor_rel_pos[i][:len(rel_pos_input)] = torch.LongTensor(rel_pos_input)            \n",
    "            \n",
    "            yield {\n",
    "                'inputs': (tensor_inputs, tensor_abs_pos, tensor_rel_pos),\n",
    "                'outputs': tensor_outputs,\n",
    "                'records': batch_records\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "timely-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = BatchIterator(all_train_data, vocabulary, 4, bpe_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "binary-lambda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs': (tensor([[[   27,     3,  1384,  ..., 12153,  6919,     8],\n",
      "         [   27,     3,    35,  ...,     0,     0,     0],\n",
      "         [   27,     3,    69,  ...,     0,     0,     0],\n",
      "         ...,\n",
      "         [   27,     3,  5443,  ...,     0,     0,     0],\n",
      "         [   27,     3,  1384,  ...,     0,     0,     0],\n",
      "         [   27,     3,  1147,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[   27,     3,  1851,  ...,     0,     0,     0],\n",
      "         [   27,     3,  6347,  ...,     0,     0,     0],\n",
      "         [   27,     3,  1384,  ...,     0,     0,     0],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[   27,     3,  6022,  ...,     0,     0,     0],\n",
      "         [   27,     3,  1147,  ...,  8186,   650,    41],\n",
      "         [   27,     3,  1384,  ...,     0,     0,     0],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[   27,     3,  1728,  ...,  1351,  2858,  4462],\n",
      "         [   27,     3,  2129,  ...,     0,     0,     0],\n",
      "         [   27,     3,   208,  ...,     0,     0,     0],\n",
      "         ...,\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0],\n",
      "         [    0,     0,     0,  ...,     0,     0,     0]]]), tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24]]), tensor([[1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
      "         4],\n",
      "        [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 2, 2, 3, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])), 'outputs': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0.]]), 'records': [{'text': 'Российский рынок акций растет, отыгрывая внешний позитив на фоне надежд на скорое разрешение текущих долговых проблем греции, а также после поддерживающих выступлений главы фрс сша бена бернанке, говорят фондовые аналитики, опрошенные риа новости. Индекс ммвб к 11.12 мск вырос на 1% - до 1565,67 пункта, а индекс ртс - на 1,5%, до 1656,51 пункта, свидетельствуют данные биржи ммвб-ртс. Греция дает надежду Во вторник появилась информация о том, что премьер-министр греции лукас пападимос вечером представит лидерам трех партий на рассмотрение проект финального соглашения с международными кредиторами, подразумевающего значительные сокращения государственных расходов в обмен на разблокирования второго пакета финпомощи от ес и мвф. затем стало известно, что соглашение греции с государственными и частными кредиторами отложено до среды, пападимос отложил еще на день встречу с лидерами партий. Она должна начаться в среду в полдень. Рост спроса на риск Российский рынок акций в начале торгов среды растет на фоне улучшения внешней конъюнктуры. Рост надежд на скорое разрешение проблем, мешающих предоставлению греции 130-миллиардного пакета финансовой помощи от \"тройки\" (ецб, мвф и еврокомиссии), подстегнул интерес инвесторов к рисковым активам. Курс евро на forex превысил психологически значимый уровень 1,32 доллара, нацелился на уровень 1,33 доллара, достигнув практически двухмесячного максимума, говорят трейдеры. На этом фоне стоимость нефти остается высокой (около 116,5 доллара за баррель по марке brent). Курс рубля растет к бивалютной корзине и особенно к доллару (американская валюта уже упала до 29,65 рублей - минимума с начала сентября 2011 года). В результате растет спрос на российские акции, а индекс ммвб опять вернулся выше важного уровня 1550 пунктов. Лидеры роста и падения Лучше рынка торгуются привилегированные акции \"транснефти\"  (+2,8%). Акции \"автоваза\"  растут на 1,9%, рдр на акции \"русала\"  - на 6,4%. Хуже рынка торгуются акции \"седьмого континента\"  (-1%). Прогнозы Внешние факторы заложили прекрасный фундамент для продолжения роста на российском рынке, считает директор аналитического департамента компании \"алемар\" василий конузин. \"мы полагаем, что сегодня индекс ммвб постарается закрепиться вблизи уровня 1570 пунктов, взятие которого откроет ему дорогу к заветным 1600 пунктам\", - сказал он. Заявления главы фрс сша бена бернанке удерживают фондовые индексы от коррекции, несмотря на имеющиеся признаки перегрева рынков, отметил аналитик втб 24 станислав клещев. \"российский рынок акций находится примерно в такой же ситуации. Вчера предпринималась попытка скорректироваться вниз, которая привела лишь к тестированию на прочность ранее пройденного уровня сопротивления 1550 пунктов по индексу ммвб. Особо стоит отметить, динамику нефтяного рынка, которая определяет интерес инвесторов к отечественным бумагам. Котировки brent поднялись выше 116 долларов за баррель, что является максимальным значением за последние полгода. Так что, подъем индекса ммвб выше своих сентябрьских максимумов выглядит в этом плане вполне обоснованным\", - сказал клещев.', 'title': 'Аналитики: рынок акций рф растет вслед за интересом инвесторов к риску', 'sentences': ['Российский рынок акций растет, отыгрывая внешний позитив на фоне надежд на скорое разрешение текущих долговых проблем греции, а также после поддерживающих выступлений главы фрс сша бена бернанке, говорят фондовые аналитики, опрошенные риа новости.', 'Индекс ммвб к 11.12 мск вырос на 1% - до 1565,67 пункта, а индекс ртс - на 1,5%, до 1656,51 пункта, свидетельствуют данные биржи ммвб-ртс.', 'Греция дает надежду', 'Во вторник появилась информация о том, что премьер-министр греции лукас пападимос вечером представит лидерам трех партий на рассмотрение проект финального соглашения с международными кредиторами, подразумевающего значительные сокращения государственных расходов в обмен на разблокирования второго пакета финпомощи от ес и мвф. затем стало известно, что соглашение греции с государственными и частными кредиторами отложено до среды, пападимос отложил еще на день встречу с лидерами партий.', 'Она должна начаться в среду в полдень.', 'Рост спроса на риск', 'Российский рынок акций в начале торгов среды растет на фоне улучшения внешней конъюнктуры.', 'Рост надежд на скорое разрешение проблем, мешающих предоставлению греции 130-миллиардного пакета финансовой помощи от \"тройки\" (ецб, мвф и еврокомиссии), подстегнул интерес инвесторов к рисковым активам.', 'Курс евро на forex превысил психологически значимый уровень 1,32 доллара, нацелился на уровень 1,33 доллара, достигнув практически двухмесячного максимума, говорят трейдеры.', 'На этом фоне стоимость нефти остается высокой (около 116,5 доллара за баррель по марке brent).', 'Курс рубля растет к бивалютной корзине и особенно к доллару (американская валюта уже упала до 29,65 рублей - минимума с начала сентября 2011 года).', 'В результате растет спрос на российские акции, а индекс ммвб опять вернулся выше важного уровня 1550 пунктов.', 'Лидеры роста и падения', 'Лучше рынка торгуются привилегированные акции \"транснефти\"  (+2,8%).', 'Акции \"автоваза\"  растут на 1,9%, рдр на акции \"русала\"  - на 6,4%.', 'Хуже рынка торгуются акции \"седьмого континента\"  (-1%).', 'Прогнозы', 'Внешние факторы заложили прекрасный фундамент для продолжения роста на российском рынке, считает директор аналитического департамента компании \"алемар\" василий конузин.', '\"мы полагаем, что сегодня индекс ммвб постарается закрепиться вблизи уровня 1570 пунктов, взятие которого откроет ему дорогу к заветным 1600 пунктам\", - сказал он.', 'Заявления главы фрс сша бена бернанке удерживают фондовые индексы от коррекции, несмотря на имеющиеся признаки перегрева рынков, отметил аналитик втб 24 станислав клещев.', '\"российский рынок акций находится примерно в такой же ситуации.', 'Вчера предпринималась попытка скорректироваться вниз, которая привела лишь к тестированию на прочность ранее пройденного уровня сопротивления 1550 пунктов по индексу ммвб.', 'Особо стоит отметить, динамику нефтяного рынка, которая определяет интерес инвесторов к отечественным бумагам.', 'Котировки brent поднялись выше 116 долларов за баррель, что является максимальным значением за последние полгода.', 'Так что, подъем индекса ммвб выше своих сентябрьских максимумов выглядит в этом плане вполне обоснованным\", - сказал клещев.'], 'oracle_sentences': [20, 22], 'oracle_summary': '\"российский рынок акций находится примерно в такой же ситуации. Особо стоит отметить, динамику нефтяного рынка, которая определяет интерес инвесторов к отечественным бумагам.'}, {'text': 'Жизнь экс-премьера украины юлии тимошенко, которая голодает уже 15 дней, находится в опасности, заявил на пресс-конференции в пятницу ее соратник, первый заместитель главы партии \"батькивщина\" александр турчинов. Экс-премьер 20 апреля объявила голодовку в знак протеста против жестокого обращения с ней в колонии. По утверждению тимошенко, ее насильно перевезли из колонии в больницу \"укрзализныци\", при этом ее тащили в простыне, скрутив ноги и руки. Сотрудники колонии, по словам тимошенко, ударили ее в живот, и она от сильной боли на время потеряла сознание. \"жизни юлии владимировны (тимошенко) угрожает реальная опасность - 15 дней голодовки это много, очень тяжело и очень опасно для жизни\", сказал турчинов. В свою очередь, ее защитник, депутат сергей власенко, который также принимал участие в пресс-конференции, сообщил, что виделся с экс-премьером накануне, отметив, что тимошенко сильно похудела. \"юлия владимировна заметно похудела, она, к сожалению, в большинстве случаев лежит, только пьет воду, я не могу сказать насколько она похудела, но визуально это заметно\", - сказал власенко. Тимошенко была осуждена в октябре 2011 года на семь лет лишения свободы за превышение полномочий при подписании газового соглашения с россией в 2009 году. С конца декабря 2011 года она отбывает срок в колонии в харькове. Еще во время процесса по \"газовому\" делу тимошенко стала жаловаться на боли в спине. В середине февраля экс-премьера осмотрела медкомиссия в составе врачей из канады и германии (экс-премьер не раз заявляла о том, что не верит врачам украинского минздрава). Генпрокурор украины по рекомендации немецких медиков поручил лечить тимошенко в медучреждении вне стен колонии, для чего была выбрана харьковская клиника компании \"укрзализныця\", однако экс-премьер отказалась лечиться в ней, немецкие врачи, осмотревшие клинику, заявили, что она не подходит для лечения тимошенко. Премьер и избранный президент рф владимир путин в четверг заявил, что россия могла бы принять на лечение тимошенко, если бы это позволили украинские власти. Ранее немецкие власти сообщали, что ведут переговоры с украинской стороной о возможном лечении тимошенко в германии. Вместе с тем генпрокуратура украины подчеркивает, что лечение осужденных, в том числе тимошенко, за пределами украины не предусмотрено законом.', 'title': 'Жизнь тимошенко в опасности из-за голодовки - замглавы \"батькивщины\"', 'sentences': ['Жизнь экс-премьера украины юлии тимошенко, которая голодает уже 15 дней, находится в опасности, заявил на пресс-конференции в пятницу ее соратник, первый заместитель главы партии \"батькивщина\" александр турчинов.', 'Экс-премьер 20 апреля объявила голодовку в знак протеста против жестокого обращения с ней в колонии.', 'По утверждению тимошенко, ее насильно перевезли из колонии в больницу \"укрзализныци\", при этом ее тащили в простыне, скрутив ноги и руки.', 'Сотрудники колонии, по словам тимошенко, ударили ее в живот, и она от сильной боли на время потеряла сознание.', '\"жизни юлии владимировны (тимошенко) угрожает реальная опасность - 15 дней голодовки это много, очень тяжело и очень опасно для жизни\", сказал турчинов.', 'В свою очередь, ее защитник, депутат сергей власенко, который также принимал участие в пресс-конференции, сообщил, что виделся с экс-премьером накануне, отметив, что тимошенко сильно похудела.', '\"юлия владимировна заметно похудела, она, к сожалению, в большинстве случаев лежит, только пьет воду, я не могу сказать насколько она похудела, но визуально это заметно\", - сказал власенко.', 'Тимошенко была осуждена в октябре 2011 года на семь лет лишения свободы за превышение полномочий при подписании газового соглашения с россией в 2009 году.', 'С конца декабря 2011 года она отбывает срок в колонии в харькове.', 'Еще во время процесса по \"газовому\" делу тимошенко стала жаловаться на боли в спине.', 'В середине февраля экс-премьера осмотрела медкомиссия в составе врачей из канады и германии (экс-премьер не раз заявляла о том, что не верит врачам украинского минздрава).', 'Генпрокурор украины по рекомендации немецких медиков поручил лечить тимошенко в медучреждении вне стен колонии, для чего была выбрана харьковская клиника компании \"укрзализныця\", однако экс-премьер отказалась лечиться в ней, немецкие врачи, осмотревшие клинику, заявили, что она не подходит для лечения тимошенко.', 'Премьер и избранный президент рф владимир путин в четверг заявил, что россия могла бы принять на лечение тимошенко, если бы это позволили украинские власти.', 'Ранее немецкие власти сообщали, что ведут переговоры с украинской стороной о возможном лечении тимошенко в германии.', 'Вместе с тем генпрокуратура украины подчеркивает, что лечение осужденных, в том числе тимошенко, за пределами украины не предусмотрено законом.'], 'oracle_sentences': [13], 'oracle_summary': 'Ранее немецкие власти сообщали, что ведут переговоры с украинской стороной о возможном лечении тимошенко в германии.'}, {'text': 'Около 30 человек пострадали в понедельник утром вблизи столицы  словении любляны в результате аварии автобуса, перевозившего немецких  детей на отдых из германии в хорватию, сообщают словенские сми. Как передает агентство sta, автобус перевернулся на трассе крань -  любляна, в 20 километрах от словенской столицы, около 06.00 по местному  времени (08.00 мск), в результате шесть человек получили серьезные  ранения. По данным полиции, жизни пострадавших находятся вне опасности. Немецкие сми со ссылкой на словенский телеканал rtvslo сообщают о 20  пострадавших: пяти взрослых и 15 подростках. Сообщается, что в эвакуации пострадавших приняли участие 17 команд  скорой помощи. Большинство раненых были госпитализированы, остальные  размещены в одном из отелей краня. Пресс-секретарь полиции краня леон кедер сообщил журналистам, что в  автобусе находился 41 человек, в основном дети 14 - 15 лет и их  сопровождающие. По данным rtvslo, автобус вез 41 человека, в том числе  29 подростков, из баварии в хорватию - через словению - на каникулы.', 'title': 'Автобус с немецкими детьми перевернулся в словении, 30 пострадавших', 'sentences': ['Около 30 человек пострадали в понедельник утром вблизи столицы  словении любляны в результате аварии автобуса, перевозившего немецких  детей на отдых из германии в хорватию, сообщают словенские сми.', 'Как передает агентство sta, автобус перевернулся на трассе крань -  любляна, в 20 километрах от словенской столицы, около 06.00 по местному  времени (08.00 мск), в результате шесть человек получили серьезные  ранения.', 'По данным полиции, жизни пострадавших находятся вне опасности.', 'Немецкие сми со ссылкой на словенский телеканал rtvslo сообщают о 20  пострадавших: пяти взрослых и 15 подростках.', 'Сообщается, что в эвакуации пострадавших приняли участие 17 команд  скорой помощи.', 'Большинство раненых были госпитализированы, остальные  размещены в одном из отелей краня.', 'Пресс-секретарь полиции краня леон кедер сообщил журналистам, что в  автобусе находился 41 человек, в основном дети 14 - 15 лет и их  сопровождающие.', 'По данным rtvslo, автобус вез 41 человека, в том числе  29 подростков, из баварии в хорватию - через словению - на каникулы.'], 'oracle_sentences': [0], 'oracle_summary': 'Около 30 человек пострадали в понедельник утром вблизи столицы  словении любляны в результате аварии автобуса, перевозившего немецких  детей на отдых из германии в хорватию, сообщают словенские сми.'}, {'text': 'Ивуарийский полузащитник \"трабзонспора\" дидье зокора заявил, что если бы ему предложили выбрать между его соотечественниками, нападающим \"челси\" дидье дрогба и форвардом цска сейду думбия, то себе в команду он взял бы последнего, поскольку тот \"быстрее и моложе\". Думбия в матче 3-го круга лиги чемпионов с \"трабзонспором\" отличился дублем, и помог своей команде одержать победу со счетом 3:0. Редакция \"р-спорт\" провела текстовую трансляцию матча цска - \"трабзонспор\" >> \"я бы выбрал думбия, - ответил зокора на просьбу журналистов сравнить двух нападающих. - он моложе и быстрее, и очень пригодился бы \"трабзонспору\". К тому же дрогба играет в одном из лучших клубов мире, поэтому у думбия больше шансов оказаться в нашей команде. Хочу сказать, что рад за него, поскольку сегодня ему удалось дважды красиво забить\". Говоря об игре с московской командой, полузащитник заявил, что \"цска играл очень умно и быстро благодаря действиям думбия и вагнера лава\". \"они создали себе моменты и сумели соорудить фантастические голы\", - отметил он. Зокора считает, что у \"трабзонспора\" несмотря на неудачу остаются хорошие шансы на выход в плей-офф лиги чемпионов. \"у нас сейчас четыре очка. Если выиграем у москвичей дома, то можем рассчитывать на выход из группы\", - заявил он. После трех туров в активе цска и \" трабзонспора\" по четыре очка. Лидирует в квартете в \"интер\", на счету которого шесть баллов.', 'title': 'Футболист цска думбия быстрее игрока \"челси\" дрогба, считает зокора', 'sentences': ['Ивуарийский полузащитник \"трабзонспора\" дидье зокора заявил, что если бы ему предложили выбрать между его соотечественниками, нападающим \"челси\" дидье дрогба и форвардом цска сейду думбия, то себе в команду он взял бы последнего, поскольку тот \"быстрее и моложе\".', 'Думбия в матче 3-го круга лиги чемпионов с \"трабзонспором\" отличился дублем, и помог своей команде одержать победу со счетом 3:0.', 'Редакция \"р-спорт\" провела текстовую трансляцию матча цска - \"трабзонспор\" >>', '\"я бы выбрал думбия, - ответил зокора на просьбу журналистов сравнить двух нападающих.', '- он моложе и быстрее, и очень пригодился бы \"трабзонспору\".', 'К тому же дрогба играет в одном из лучших клубов мире, поэтому у думбия больше шансов оказаться в нашей команде.', 'Хочу сказать, что рад за него, поскольку сегодня ему удалось дважды красиво забить\".', 'Говоря об игре с московской командой, полузащитник заявил, что \"цска играл очень умно и быстро благодаря действиям думбия и вагнера лава\".', '\"они создали себе моменты и сумели соорудить фантастические голы\", - отметил он.', 'Зокора считает, что у \"трабзонспора\" несмотря на неудачу остаются хорошие шансы на выход в плей-офф лиги чемпионов.', '\"у нас сейчас четыре очка.', 'Если выиграем у москвичей дома, то можем рассчитывать на выход из группы\", - заявил он.', 'После трех туров в активе цска и \" трабзонспора\" по четыре очка.', 'Лидирует в квартете в \"интер\", на счету которого шесть баллов.'], 'oracle_sentences': [0], 'oracle_summary': 'Ивуарийский полузащитник \"трабзонспора\" дидье зокора заявил, что если бы ему предложили выбрать между его соотечественниками, нападающим \"челси\" дидье дрогба и форвардом цска сейду думбия, то себе в команду он взял бы последнего, поскольку тот \"быстрее и моложе\".'}]}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "prostate-tournament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 25, 50])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['inputs'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "legendary-corrections",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['inputs'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "blank-compromise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
       "         4],\n",
       "        [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [1, 1, 2, 2, 3, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['inputs'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "chemical-adjustment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 25])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['outputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "perfect-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "def train_model(model, train_records, val_records, vocabulary, bpe_processor, batch_size=32,\n",
    "                epochs_count=10, loss_every_nsteps=16, lr=0.001, device_name=\"cuda\"):\n",
    "    params_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Trainable params: {}\".format(params_count))\n",
    "    device = torch.device(device_name)\n",
    "    model = model.to(device)\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_function = nn.BCEWithLogitsLoss().to(device)\n",
    "    for epoch in range(epochs_count):\n",
    "        for step, batch in enumerate(BatchIterator(train_records, vocabulary, batch_size, bpe_processor, device=device)):\n",
    "            model.train()\n",
    "            logits = model(batch[\"inputs\"]) # Прямой проход\n",
    "            loss = loss_function(logits, batch[\"outputs\"]) # Подсчёт ошибки\n",
    "            loss.backward() # Подсчёт градиентов dL/dw\n",
    "            optimizer.step() # Градиентный спуск или его модификации (в данном случае Adam)\n",
    "            optimizer.zero_grad() # Зануление градиентов, чтобы их спокойно менять на следующей итерации\n",
    "            total_loss += loss.item()\n",
    "            if step % loss_every_nsteps == 0 and step != 0:\n",
    "                val_total_loss = 0\n",
    "                val_batch_count = 0\n",
    "                model.eval()\n",
    "#                 for _, val_batch in enumerate(BatchIterator(val_records, vocabulary, batch_size, bpe_processor, device=device)):\n",
    "#                     logits = model(val_batch[\"inputs\"]) # Прямой проход\n",
    "#                     val_total_loss += loss_function(logits, val_batch[\"outputs\"]) # Подсчёт ошибки\n",
    "#                     val_batch_count += 1\n",
    "#                 avg_val_loss = val_total_loss/val_batch_count\n",
    "#                 print(\"Epoch = {}, Avg Train Loss = {:.4f}, Avg val loss = {:.4f}, Time = {:.2f}s\".format(epoch, total_loss / loss_every_nsteps, avg_val_loss, time.time() - start_time))\n",
    "                print(\"Epoch = {}, Avg Train Loss = {:.4f}, Time = {:.2f}s\".format(epoch, total_loss / loss_every_nsteps, time.time() - start_time))\n",
    "                total_loss = 0\n",
    "                start_time = time.time()\n",
    "        total_loss = 0\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "indoor-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "\n",
    "class SentenceEncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3, bidirectional=True):\n",
    "        super(SentenceEncoderRNN, self).__init__()\n",
    "\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        assert hidden_size % num_directions == 0\n",
    "        hidden_size = hidden_size // num_directions\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.embedding_layer = nn.Embedding(input_size, embedding_dim)\n",
    "        self.rnn_layer = nn.LSTM(embedding_dim, hidden_size, n_layers, dropout=dropout, bidirectional=bidirectional, batch_first=True)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        embedded = self.embedding_layer(inputs)\n",
    "        outputs, _ = self.rnn_layer(embedded, hidden)\n",
    "        sentences_embeddings = torch.mean(outputs, 1)\n",
    "        return sentences_embeddings\n",
    "\n",
    "class SentenceTaggerRNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 token_embedding_dim=256,\n",
    "                 sentence_encoder_hidden_size=256,\n",
    "                 hidden_size=256,\n",
    "                 bidirectional=True,\n",
    "                 sentence_encoder_n_layers=2,\n",
    "                 sentence_encoder_dropout=0.3,\n",
    "                 sentence_encoder_bidirectional=True,\n",
    "                 n_layers=1,\n",
    "                 dropout=0.3):\n",
    "        super(SentenceTaggerRNN, self).__init__()\n",
    "\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        assert hidden_size % num_directions == 0\n",
    "        hidden_size = hidden_size // num_directions\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.sentence_encoder = SentenceEncoderRNN(vocabulary_size, token_embedding_dim,\n",
    "                                                   sentence_encoder_hidden_size, sentence_encoder_n_layers, \n",
    "                                                   sentence_encoder_dropout, sentence_encoder_bidirectional)\n",
    "        self.rnn_layer = nn.LSTM(sentence_encoder_hidden_size, hidden_size, n_layers, dropout=dropout,\n",
    "                           bidirectional=bidirectional, batch_first=True)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        self.content_linear_layer = nn.Linear(hidden_size * 2, 1)\n",
    "        self.document_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.salience_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.tanh_layer = nn.Tanh()\n",
    "        \n",
    "        self.output_bias = nn.Parameter(torch.ones(1))\n",
    "        # max_sentences\n",
    "        self.abs_pos_emb = nn.Embedding(30, 1)\n",
    "        self.rel_pos_emb = nn.Embedding(6, 1)\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        embeddings_input = inputs[0]\n",
    "        abs_pos_input = inputs[1]\n",
    "        rel_pos_input = inputs[2]\n",
    "        batch_size = embeddings_input.size(0)\n",
    "        sentences_count = embeddings_input.size(1)\n",
    "        tokens_count = embeddings_input.size(2)\n",
    "        embeddings_input = embeddings_input.reshape(-1, tokens_count)\n",
    "        embedded_sentences = self.sentence_encoder(embeddings_input)\n",
    "        embedded_sentences = embedded_sentences.reshape(batch_size, sentences_count, -1)\n",
    "        outputs, _ = self.rnn_layer(embedded_sentences, hidden)\n",
    "        outputs = self.dropout_layer(outputs)\n",
    "        document_embedding = self.tanh_layer(self.document_linear_layer(torch.mean(outputs, 1)))\n",
    "        content = self.content_linear_layer(outputs).squeeze(2)\n",
    "        salience = torch.bmm(outputs, self.salience_linear_layer(document_embedding).unsqueeze(2)).squeeze(2)\n",
    "        rel_pos_embedding = self.rel_pos_emb(rel_pos_input).squeeze()\n",
    "        abs_pos_embedding = self.abs_pos_emb(abs_pos_input).squeeze()\n",
    "        # (batch_size, max_sentences)\n",
    "        return content + salience + self.output_bias + rel_pos_embedding + abs_pos_embedding  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "legal-longer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 5356326\n",
      "Epoch = 0, Avg Train Loss = 0.4611, Time = 4.46s\n",
      "Epoch = 0, Avg Train Loss = 0.1098, Time = 4.04s\n",
      "Epoch = 0, Avg Train Loss = 0.0882, Time = 4.08s\n",
      "Epoch = 0, Avg Train Loss = 0.0824, Time = 4.04s\n",
      "Epoch = 0, Avg Train Loss = 0.0792, Time = 4.11s\n",
      "Epoch = 0, Avg Train Loss = 0.0884, Time = 4.05s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-0148e3f75665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTaggerRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_test_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpe_processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-87-821465259a66>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_records, val_records, vocabulary, bpe_processor, batch_size, epochs_count, loss_every_nsteps, lr, device_name)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Прямой проход\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Подсчёт ошибки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Подсчёт градиентов dL/dw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Градиентный спуск или его модификации (в данном случае Adam)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Зануление градиентов, чтобы их спокойно менять на следующей итерации\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_project/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_project/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SentenceTaggerRNN(vocabulary.size())\n",
    "train_model(model, all_train_data, all_test_data, vocabulary, bpe_processor, device_name=\"cuda\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-attempt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "invisible-thanksgiving",
   "metadata": {},
   "source": [
    "+ +summary relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "homeless-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "\n",
    "class SentenceEncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3, bidirectional=True):\n",
    "        super(SentenceEncoderRNN, self).__init__()\n",
    "\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        assert hidden_size % num_directions == 0\n",
    "        hidden_size = hidden_size // num_directions\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.embedding_layer = nn.Embedding(input_size, embedding_dim)\n",
    "        self.rnn_layer = nn.LSTM(embedding_dim, hidden_size, n_layers, dropout=dropout, bidirectional=bidirectional, batch_first=True)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        embedded = self.embedding_layer(inputs)\n",
    "        outputs, _ = self.rnn_layer(embedded, hidden)\n",
    "        sentences_embeddings = torch.mean(outputs, 1)\n",
    "        return sentences_embeddings\n",
    "\n",
    "class SentenceTaggerRNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 token_embedding_dim=256,\n",
    "                 sentence_encoder_hidden_size=256,\n",
    "                 hidden_size=256,\n",
    "                 bidirectional=True,\n",
    "                 sentence_encoder_n_layers=2,\n",
    "                 sentence_encoder_dropout=0.3,\n",
    "                 sentence_encoder_bidirectional=True,\n",
    "                 n_layers=1,\n",
    "                 dropout=0.3):\n",
    "        super(SentenceTaggerRNN, self).__init__()\n",
    "\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        assert hidden_size % num_directions == 0\n",
    "        hidden_size = hidden_size // num_directions\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.sentence_encoder = SentenceEncoderRNN(vocabulary_size, token_embedding_dim,\n",
    "                                                   sentence_encoder_hidden_size, sentence_encoder_n_layers, \n",
    "                                                   sentence_encoder_dropout, sentence_encoder_bidirectional)\n",
    "        self.rnn_layer = nn.LSTM(sentence_encoder_hidden_size, hidden_size, n_layers, dropout=dropout,\n",
    "                           bidirectional=bidirectional, batch_first=True)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        self.content_linear_layer = nn.Linear(hidden_size * 2, 1)\n",
    "        self.document_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.salience_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.tanh_layer = nn.Tanh()\n",
    "        \n",
    "        self.output_bias = nn.Parameter(torch.ones(1))\n",
    "        self.abs_pos_emb = nn.Embedding(30, 1)\n",
    "        self.rel_pos_emb = nn.Embedding(6, 1)\n",
    "        self.novelty_tanh_layer = nn.Tanh()\n",
    "        self.novelty_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        embeddings_input = inputs[0]\n",
    "        abs_pos_input = inputs[1]\n",
    "        rel_pos_input = inputs[2]\n",
    "        batch_size = embeddings_input.size(0)\n",
    "        sentences_count = embeddings_input.size(1)\n",
    "        tokens_count = embeddings_input.size(2)\n",
    "        embeddings_input = embeddings_input.reshape(-1, tokens_count)\n",
    "        embedded_sentences = self.sentence_encoder(embeddings_input)\n",
    "        embedded_sentences = embedded_sentences.reshape(batch_size, sentences_count, -1)\n",
    "        outputs, _ = self.rnn_layer(embedded_sentences, hidden)\n",
    "        outputs = self.dropout_layer(outputs) # h [32, 30, 256]\n",
    "        document_embedding = self.tanh_layer(self.document_linear_layer(torch.mean(outputs, 1))) # [32, 256]\n",
    "        content = self.content_linear_layer(outputs).squeeze(2)\n",
    "        # self.salience_linear_layer(document_embedding).unsqueeze(2) [32, 256, 1]\n",
    "        # [32, 30, 256] * [32, 256, 1] -> [32, 30]\n",
    "        salience = torch.bmm(outputs, self.salience_linear_layer(document_embedding).unsqueeze(2)).squeeze(2)\n",
    "        rel_pos_embedding = self.rel_pos_emb(rel_pos_input).squeeze()\n",
    "        abs_pos_embedding = self.abs_pos_emb(abs_pos_input).squeeze()\n",
    "        pred_wo_summary = content + salience + self.output_bias + rel_pos_embedding + abs_pos_embedding # [32, 30]\n",
    "        \n",
    "        pred_summary = pred_wo_summary.clone().detach()\n",
    "        \n",
    "        novelty_vector = torch.zeros((batch_size, sentences_count), dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "        sliding_summary_first_element = torch.zeros((batch_size, self.hidden_size * 2), dtype=torch.float32, device=\"cuda\")\n",
    "        sliding_summary = torch.zeros((batch_size, sentences_count, self.hidden_size * 2), dtype=torch.float32, device=\"cuda\")\n",
    "        sliding_summary[:, 0, :] = sliding_summary_first_element.clone() \n",
    "\n",
    "        # for each sentence\n",
    "        for i in range(1, sentences_count):\n",
    "            # calc p[i-1]\n",
    "            weighted_sum = self.novelty_linear_layer(torch.tanh(sliding_summary[:, i - 1, :].clone().squeeze())).unsqueeze(2) # -> [32, 256, 1]\n",
    "            novelty_vector[:, i - 1] = torch.bmm(outputs[:, i - 1, :].clone().unsqueeze(1),  weighted_sum).squeeze() # [32]\n",
    "            pred_summary[:, i - 1] = pred_summary[:, i - 1].clone()  - novelty_vector[:, i - 1].clone()  \n",
    "            \n",
    "            # calc sliding_summary\n",
    "            final_s = sliding_summary_first_element.clone().detach()\n",
    "            for j in range(i):\n",
    "                final_s += torch.matmul(pred_summary[:, j].clone(), outputs[:, j, :].clone().squeeze()) # [32, 256]\n",
    "            sliding_summary[:, i, :] = final_s.clone()\n",
    "                  \n",
    "        return pred_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-progressive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 5422118\n",
      "Epoch = 0, Avg Train Loss = 0.6305, Time = 12.27s\n",
      "Epoch = 0, Avg Train Loss = 0.2640, Time = 10.95s\n",
      "Epoch = 0, Avg Train Loss = 0.2223, Time = 10.85s\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTaggerRNN(vocabulary.size())\n",
    "train_model(model, all_train_data, all_test_data, vocabulary, bpe_processor, device_name=\"cuda\", batch_size=32, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-tumor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-potter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-offer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "least-sphere",
   "metadata": {},
   "source": [
    "+ +BERT pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "automated-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "bert_model_path = 'rubert_cased_L-12_H-768_A-12_pt'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_path)\n",
    "model = BertModel.from_pretrained(bert_model_path)\n",
    "embeddings = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bigger-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import razdel\n",
    "import torch\n",
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "\n",
    "\n",
    "class BatchIterator():\n",
    "    def __init__(self, records, batch_size, tokenizer, embeddings, shuffle=True, lower=True, max_sentences=30, max_sentence_length=50, device=torch.device('cpu')):\n",
    "        self.records = records\n",
    "        self.num_samples = len(records)\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.shuffle = shuffle\n",
    "        self.batches_count = int(math.ceil(self.num_samples / batch_size))\n",
    "        self.lower = lower\n",
    "        self.rouge = Rouge()\n",
    "        self.embeddings = embeddings\n",
    "        self.max_sentences = max_sentences\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.batches_count\n",
    "    \n",
    "    def __iter__(self):\n",
    "        indices = np.arange(self.num_samples)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "        for start in range(0, self.num_samples, self.batch_size):\n",
    "            end = min(start + self.batch_size, self.num_samples)\n",
    "            batch_indices = indices[start:end]\n",
    "            batch_inputs = []\n",
    "            batch_outputs = []\n",
    "            rel_pos_inputs = []\n",
    "            max_sentence_length = 0\n",
    "            max_sentences = 0\n",
    "            batch_records = []\n",
    "            # свой max_sentences для батча\n",
    "            for data_ind in batch_indices:\n",
    "                record = self.records[data_ind]\n",
    "                batch_records.append(record)\n",
    "                text = record[\"text\"]\n",
    "                summary = record[\"title\"]\n",
    "                summary = summary.lower() if self.lower else summary\n",
    "\n",
    "                if \"sentences\" not in record:\n",
    "                    sentences = [sentence.text.lower() if self.lower else sentence.text for sentence in razdel.sentenize(text)][:self.max_sentences]\n",
    "                else:\n",
    "                    sentences = record[\"sentences\"]\n",
    "                max_sentences = max(len(sentences), max_sentences)\n",
    "\n",
    "                if \"oracle_sentences\" not in record:\n",
    "                    calc_score = lambda x, y: calc_single_score(x, y, self.rouge)\n",
    "                    sentences_indicies = build_oracle_summary_greedy(text, summary, calc_score=calc_score, lower=self.lower, max_sentences=self.max_sentences)[1]\n",
    "                else:\n",
    "                    sentences_indicies = record[\"oracle_sentences\"]\n",
    "                \n",
    "                # len(sentences)\n",
    "                # inputs = [list(map(self.vocabulary.get_index, bpe_tokenize(sentence, self.bpe_processor)[:self.max_sentence_length])) for sentence in sentences]\n",
    "                tokenized_inputs = [self.tokenizer(sentence) for sentence in sentences]\n",
    "                inputs = [self.embeddings(torch.LongTensor(sent['input_ids'][1:(self.max_sentence_length + 1)])) for sent in tokenized_inputs]\n",
    "                max_sentence_length = max(max_sentence_length, max([tokens.shape[0] for tokens in inputs]))\n",
    "                # len(sentences)\n",
    "                outputs = [int(i in sentences_indicies) for i in range(len(sentences))]\n",
    "                # rel_pos\n",
    "                pos = [i / len(sentences) for i in range(len(sentences))]\n",
    "                bins = np.array([0.25, 0.5, 0.75, 1.0])\n",
    "                # possible options array([1, 2, 3, 4, 5])\n",
    "                rel_pos_inds = np.digitize(np.array([p for p in pos]), bins) + 1\n",
    "                rel_pos_inputs.append(rel_pos_inds)\n",
    "                batch_inputs.append(inputs)\n",
    "                batch_outputs.append(outputs)\n",
    "            # 768 - BERT embeddings size\n",
    "            tensor_inputs = torch.zeros((self.batch_size, max_sentences, max_sentence_length, 768), dtype=torch.float32, device=self.device)\n",
    "            tensor_outputs = torch.zeros((self.batch_size, max_sentences), dtype=torch.float32, device=self.device)\n",
    "            tensor_abs_pos = torch.zeros((self.batch_size, max_sentences), dtype=torch.long, device=self.device)\n",
    "            tensor_rel_pos = torch.zeros((self.batch_size, max_sentences), dtype=torch.long, device=self.device)\n",
    "            for i, inputs in enumerate(batch_inputs):\n",
    "                for j, sentence_tokens in enumerate(inputs):\n",
    "                    tensor_inputs[i][j][:len(sentence_tokens)] = torch.FloatTensor(sentence_tokens)\n",
    "            for i, outputs in enumerate(batch_outputs):\n",
    "                tensor_outputs[i][:len(outputs)] = torch.LongTensor(outputs)\n",
    "                # abs pos\n",
    "                tensor_abs_pos[i] = torch.LongTensor([i for i in range(max_sentences)])\n",
    "            # rel pos\n",
    "            for i, rel_pos_input in enumerate(rel_pos_inputs):\n",
    "                tensor_rel_pos[i][:len(rel_pos_input)] = torch.LongTensor(rel_pos_input)            \n",
    "            \n",
    "            yield {\n",
    "                'inputs': (tensor_inputs, tensor_abs_pos, tensor_rel_pos),\n",
    "                'outputs': tensor_outputs,\n",
    "                'records': batch_records\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dying-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = BatchIterator(all_train_data, 4, tokenizer, embeddings, shuffle=True, lower=True, max_sentences=30, max_sentence_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rubber-ethernet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs': (tensor([[[[ 4.9386e-02,  3.7106e-02, -2.3729e-02,  ..., -3.7180e-02,\n",
      "           -4.1990e-02,  1.4780e-02],\n",
      "          [ 6.2526e-03,  8.8256e-03, -1.9241e-02,  ..., -3.9275e-02,\n",
      "           -8.4364e-03, -9.6094e-03],\n",
      "          [ 1.5999e-02,  4.4575e-02, -1.7758e-02,  ...,  4.9740e-03,\n",
      "           -6.5474e-03, -3.5632e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.4203e-02,  1.5657e-02, -1.8927e-03,  ..., -3.3525e-02,\n",
      "           -1.9459e-03, -8.4745e-03],\n",
      "          [ 2.1707e-02,  2.9045e-02, -1.2116e-02,  ..., -3.9621e-02,\n",
      "           -4.3472e-02,  5.9852e-03],\n",
      "          [-6.9191e-02,  4.1258e-02, -5.6599e-02,  ...,  1.1496e-02,\n",
      "            1.5002e-02, -2.2854e-02],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-5.0771e-02,  2.2437e-02,  1.3640e-02,  ...,  2.4586e-02,\n",
      "           -5.1727e-02,  3.0279e-03],\n",
      "          [-3.6259e-02,  7.4582e-04, -2.9495e-02,  ..., -4.6120e-02,\n",
      "           -2.6997e-02, -3.0334e-02],\n",
      "          [ 2.8786e-02, -2.2881e-02, -2.6395e-02,  ..., -3.5231e-02,\n",
      "           -2.1994e-02, -2.1989e-02],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4263e-02,  4.5979e-02, -4.6559e-04,  ...,  7.2602e-02,\n",
      "           -5.5174e-02, -2.1257e-02],\n",
      "          [-3.5292e-03,  1.6931e-02, -1.1946e-02,  ..., -2.5439e-02,\n",
      "            1.9389e-02, -8.9907e-03],\n",
      "          [-4.0125e-02,  4.0987e-02,  1.2896e-02,  ..., -2.6304e-02,\n",
      "            2.8296e-02, -1.0474e-01],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 4.9828e-03,  1.8797e-02,  2.7093e-02,  ...,  8.2692e-02,\n",
      "            1.3464e-02,  4.3688e-02],\n",
      "          [-1.1444e-02,  1.0079e-02,  1.3080e-02,  ..., -2.5664e-02,\n",
      "           -2.1784e-02,  3.2452e-02],\n",
      "          [-1.9887e-02,  4.0924e-02,  6.1253e-02,  ..., -3.5306e-02,\n",
      "           -3.7259e-02,  1.8906e-02],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-5.0771e-02,  2.2437e-02,  1.3640e-02,  ...,  2.4586e-02,\n",
      "           -5.1727e-02,  3.0279e-03],\n",
      "          [-3.6259e-02,  7.4582e-04, -2.9495e-02,  ..., -4.6120e-02,\n",
      "           -2.6997e-02, -3.0334e-02],\n",
      "          [ 2.8786e-02, -2.2881e-02, -2.6395e-02,  ..., -3.5231e-02,\n",
      "           -2.1994e-02, -2.1989e-02],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.5489e-02,  2.6737e-02,  1.1953e-03,  ..., -1.1115e-02,\n",
      "           -2.8139e-02, -1.5886e-02],\n",
      "          [ 3.4598e-02,  2.9519e-02,  2.5014e-04,  ...,  2.7793e-02,\n",
      "            4.5997e-02, -3.2455e-02],\n",
      "          [-1.2366e-02,  2.7892e-02, -4.0001e-02,  ..., -3.6341e-02,\n",
      "           -8.6148e-03, -1.9337e-02],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.7794e-02,  5.1893e-02, -2.7214e-03,  ...,  2.4982e-02,\n",
      "            5.0308e-03,  3.2709e-02],\n",
      "          [-2.1497e-02,  2.8768e-02,  1.9927e-03,  ..., -2.4580e-02,\n",
      "            1.1006e-02,  5.0056e-03],\n",
      "          [-4.8194e-03,  4.8746e-03, -2.0243e-02,  ...,  1.1421e-03,\n",
      "           -2.7664e-02,  7.1664e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.1054e-02,  3.8840e-02,  4.1818e-02,  ...,  1.3684e-02,\n",
      "            1.8713e-03, -1.6821e-02],\n",
      "          [ 1.9722e-02,  4.3240e-02,  3.1593e-02,  ..., -2.3090e-02,\n",
      "            3.7335e-02, -9.9460e-03],\n",
      "          [-1.4999e-02, -1.4003e-03, -1.5089e-02,  ..., -2.1837e-02,\n",
      "            4.3572e-03, -5.9040e-02],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.4999e-02, -1.4003e-03, -1.5089e-02,  ..., -2.1837e-02,\n",
      "            4.3572e-03, -5.9040e-02],\n",
      "          [-3.4883e-02,  2.5648e-02,  1.0535e-02,  ..., -2.3655e-02,\n",
      "           -2.2172e-02,  6.2335e-03],\n",
      "          [-3.3506e-02,  1.2268e-02, -2.1455e-02,  ..., -1.7005e-02,\n",
      "           -4.7906e-02, -1.9818e-02],\n",
      "          ...,\n",
      "          [-3.4850e-02,  1.7277e-02, -9.7598e-04,  ..., -3.7926e-02,\n",
      "           -2.7435e-02, -2.6099e-02],\n",
      "          [-1.7813e-03,  1.0370e-02,  2.8005e-02,  ..., -1.4255e-02,\n",
      "           -4.2589e-02, -3.0842e-02],\n",
      "          [ 3.6962e-02,  1.2904e-02, -1.2629e-02,  ..., -4.6699e-02,\n",
      "           -2.0785e-02, -3.5625e-03]],\n",
      "\n",
      "         [[ 2.7794e-02,  5.1893e-02, -2.7214e-03,  ...,  2.4982e-02,\n",
      "            5.0308e-03,  3.2709e-02],\n",
      "          [-3.7235e-02,  1.2975e-02, -2.9822e-02,  ..., -3.0091e-02,\n",
      "           -3.7126e-02, -8.6511e-03],\n",
      "          [-1.5998e-02,  4.6010e-02,  2.4330e-02,  ..., -7.5701e-03,\n",
      "           -6.7363e-03,  1.8781e-02],\n",
      "          ...,\n",
      "          [-3.0584e-02,  7.5513e-03, -2.3122e-02,  ..., -7.1508e-02,\n",
      "            5.6608e-03, -4.1935e-03],\n",
      "          [ 3.1115e-02,  1.6741e-02, -3.0619e-04,  ..., -2.9423e-02,\n",
      "           -4.5025e-02, -1.9027e-02],\n",
      "          [-9.9991e-03, -1.6912e-02, -1.8645e-02,  ..., -2.6062e-02,\n",
      "           -5.0932e-02, -1.2031e-02]],\n",
      "\n",
      "         [[ 3.4113e-02,  3.9024e-02, -1.4393e-02,  ...,  1.8841e-02,\n",
      "           -2.4103e-02, -1.1764e-02],\n",
      "          [-2.3494e-02,  2.1719e-02,  9.0338e-03,  ..., -5.0779e-02,\n",
      "           -2.3237e-02, -2.3141e-02],\n",
      "          [ 2.8414e-03,  2.0600e-02,  1.5742e-02,  ...,  1.3574e-03,\n",
      "            4.7438e-03, -1.0784e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.4875e-02,  2.9511e-02,  6.7539e-02,  ...,  3.0932e-02,\n",
      "           -4.2196e-02,  1.6638e-02],\n",
      "          [-7.5792e-03,  1.8509e-02,  1.9027e-02,  ..., -1.2588e-02,\n",
      "           -1.0464e-02,  1.2451e-03],\n",
      "          [ 2.0145e-02,  3.3491e-02, -2.0732e-02,  ...,  2.0742e-02,\n",
      "           -1.2899e-02, -2.1910e-02],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.7794e-02,  5.1893e-02, -2.7214e-03,  ...,  2.4982e-02,\n",
      "            5.0308e-03,  3.2709e-02],\n",
      "          [ 1.8294e-02,  4.8107e-02,  3.9887e-02,  ...,  2.1215e-02,\n",
      "           -4.2942e-02, -2.2215e-02],\n",
      "          [-1.8511e-06,  1.9917e-02, -5.1250e-03,  ...,  1.0931e-02,\n",
      "           -5.9803e-03,  2.0018e-02],\n",
      "          ...,\n",
      "          [ 1.1484e-02, -4.3014e-04,  2.3218e-02,  ..., -1.1730e-02,\n",
      "            3.2096e-03, -3.5716e-02],\n",
      "          [-2.4357e-02,  2.4025e-02, -2.9424e-03,  ..., -1.1963e-03,\n",
      "           -4.3610e-02, -1.8896e-02],\n",
      "          [-6.0333e-02,  3.6426e-02, -2.6941e-02,  ..., -6.9157e-02,\n",
      "            3.2925e-02, -1.9766e-02]],\n",
      "\n",
      "         [[ 1.1054e-02,  3.8840e-02,  4.1818e-02,  ...,  1.3684e-02,\n",
      "            1.8713e-03, -1.6821e-02],\n",
      "          [ 1.4352e-02,  1.3316e-02, -2.3108e-02,  ..., -2.0186e-02,\n",
      "           -4.2902e-02, -1.2334e-02],\n",
      "          [ 1.5999e-02,  4.4575e-02, -1.7758e-02,  ...,  4.9740e-03,\n",
      "           -6.5474e-03, -3.5632e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]]]], grad_fn=<CopySlices>), tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]), tensor([[1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4],\n",
      "        [1, 2, 3, 4, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 2, 3, 4, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0]])), 'outputs': tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'records': [{'text': 'Число политиков, так или иначе втянутых в спор о том, как германии следует вести себя по отношению к россии, растет, пишут немецкие сми. Комментируя недавнее заявление главы христианско-социальный союза (хсс) хорста зеехофера, координатор германо-российского сотрудничества гернот эрлер обвинил его в небрежности. Зеехофер ранее потребовал от председателя социал-демократической партии германии (сдпг) зигмара габриэля выяснить, насколько его однопартийцы поддерживают политику ангелы меркель по отношению к россии. Соответствующий вопрос он пообещал вынести на обсуждение 25 ноября, когда состоится встреча лидеров сдпг и христианско-демократического союза. По словам эрлера, премьер-министр баварии своими замечаниями спровоцировал \"международное замешательство без реальных причин\". Требования зеехофера подверг критике не только эрлер. В частности, нильс аннен, еще один представитель сдпг, назвал высказывания премьер-министра баварии \"слишком колкими\". Его однопартиец рольф мютцених, в свою очередь, обратил внимание на связи с россией, имеющиеся у представителей партии зеехофера хсс. Ранее немецкие сми сообщали о том, что позиции канцлера ангелы меркель и министра штайнмайера, члена сдпг, по отношению к россии в свете украинского конфликта, несколько расходятся. Если меркель заявляла ранее, что запад не должен быть \"слишком добродушным\" по отношению к действиям рф, то штайнмайер, напротив, призывал к сдержанности. Зеехофер в интервью der spiegel подверг критике высказывания штайнмайера, обвинив его, в частности, в том, что он \"ведет свою собственную дипломатию одновременно с меркель\".', 'title': 'Сми: немецкие политики спорят из-за отношения к россии', 'sentences': ['Число политиков, так или иначе втянутых в спор о том, как германии следует вести себя по отношению к россии, растет, пишут немецкие сми.', 'Комментируя недавнее заявление главы христианско-социальный союза (хсс) хорста зеехофера, координатор германо-российского сотрудничества гернот эрлер обвинил его в небрежности.', 'Зеехофер ранее потребовал от председателя социал-демократической партии германии (сдпг) зигмара габриэля выяснить, насколько его однопартийцы поддерживают политику ангелы меркель по отношению к россии.', 'Соответствующий вопрос он пообещал вынести на обсуждение 25 ноября, когда состоится встреча лидеров сдпг и христианско-демократического союза.', 'По словам эрлера, премьер-министр баварии своими замечаниями спровоцировал \"международное замешательство без реальных причин\".', 'Требования зеехофера подверг критике не только эрлер.', 'В частности, нильс аннен, еще один представитель сдпг, назвал высказывания премьер-министра баварии \"слишком колкими\".', 'Его однопартиец рольф мютцених, в свою очередь, обратил внимание на связи с россией, имеющиеся у представителей партии зеехофера хсс.', 'Ранее немецкие сми сообщали о том, что позиции канцлера ангелы меркель и министра штайнмайера, члена сдпг, по отношению к россии в свете украинского конфликта, несколько расходятся.', 'Если меркель заявляла ранее, что запад не должен быть \"слишком добродушным\" по отношению к действиям рф, то штайнмайер, напротив, призывал к сдержанности.', 'Зеехофер в интервью der spiegel подверг критике высказывания штайнмайера, обвинив его, в частности, в том, что он \"ведет свою собственную дипломатию одновременно с меркель\".'], 'oracle_sentences': [2], 'oracle_summary': 'Зеехофер ранее потребовал от председателя социал-демократической партии германии (сдпг) зигмара габриэля выяснить, насколько его однопартийцы поддерживают политику ангелы меркель по отношению к россии.'}, {'text': 'Глава минэкономразвития алексей улюкаев заявил, что не понял бы решения вернуть башнефть в госсобственность. \"мне непонятно такое решение\", — сказал он журналистам в пятницу, отвечая на вопрос, как он относится к возможной передаче башнефти в госсобственность. В четверг суд по заявлению генеральной прокуратуры рф арестовал 74% акций нефтяной компании \"башнефть\", принадлежащие оао афк \"система\" и зао \"система-инвест\". По информации генпрокуратуры, были допущены нарушения при отчуждении предприятий тэк в башкирии.', 'title': 'Улюкаев счел бы непонятным возвращение башнефти в госсобственность', 'sentences': ['Глава минэкономразвития алексей улюкаев заявил, что не понял бы решения вернуть башнефть в госсобственность.', '\"мне непонятно такое решение\", — сказал он журналистам в пятницу, отвечая на вопрос, как он относится к возможной передаче башнефти в госсобственность.', 'В четверг суд по заявлению генеральной прокуратуры рф арестовал 74% акций нефтяной компании \"башнефть\", принадлежащие оао афк \"система\" и зао \"система-инвест\".', 'По информации генпрокуратуры, были допущены нарушения при отчуждении предприятий тэк в башкирии.'], 'oracle_sentences': [1], 'oracle_summary': '\"мне непонятно такое решение\", — сказал он журналистам в пятницу, отвечая на вопрос, как он относится к возможной передаче башнефти в госсобственность.'}, {'text': 'Суд признал директора омской \"автошколы 55\" александра гринева виновным в даче взятки инспектору гибдд за содействие в получении прав восьми ученикам и приговорил его к штрафу в размере 40 тысяч рублей, сообщило региональное управление следственного комитета в четверг. \"тридцатого мая обвиняемый в служебном кабинете мэо гибдд полиции умвд россии по омской области пытался передать инспектору в виде взятки 24 тысячи рублей за оказание содействия восьми ученикам учебного центра в сдаче государственного квалификационного экзамена. После передачи денежных средств подозреваемый был задержан сотрудниками полиции\", — говорится в сообщении. Суд признал директора виновным по статье \"покушение на дачу взятки должностному лицу\" и назначил ему штраф. Решение суда в законную силу не вступило и может быть обжаловано.', 'title': 'Суд оштрафовал директора омской автошколы за дачу взятки инспектору', 'sentences': ['Суд признал директора омской \"автошколы 55\" александра гринева виновным в даче взятки инспектору гибдд за содействие в получении прав восьми ученикам и приговорил его к штрафу в размере 40 тысяч рублей, сообщило региональное управление следственного комитета в четверг.', '\"тридцатого мая обвиняемый в служебном кабинете мэо гибдд полиции умвд россии по омской области пытался передать инспектору в виде взятки 24 тысячи рублей за оказание содействия восьми ученикам учебного центра в сдаче государственного квалификационного экзамена.', 'После передачи денежных средств подозреваемый был задержан сотрудниками полиции\", — говорится в сообщении.', 'Суд признал директора виновным по статье \"покушение на дачу взятки должностному лицу\" и назначил ему штраф.', 'Решение суда в законную силу не вступило и может быть обжаловано.'], 'oracle_sentences': [0, 3], 'oracle_summary': 'Суд признал директора омской \"автошколы 55\" александра гринева виновным в даче взятки инспектору гибдд за содействие в получении прав восьми ученикам и приговорил его к штрафу в размере 40 тысяч рублей, сообщило региональное управление следственного комитета в четверг. Суд признал директора виновным по статье \"покушение на дачу взятки должностному лицу\" и назначил ему штраф.'}, {'text': 'Попытки привлечь запад к взаимодействию в борьбе с угрозами от боевиков в отношении вывоза химоружия в сирии не получили адекватной реакции, заявили во вторник в мид рф. \"к сожалению, наши попытки привлечь западные страны к реальному взаимодействию с целью нивелирования исходящих со стороны незаконных вооруженных формирований угроз в отношении операции по вывозу компонентов химоружия (из сирии) так и не получили адекватной реакции. В частности, не было поддержано наше предложение принять на этот счет специальное заявление председателя совета безопасности оон\", — говорится в комментарии мид рф, размещенном на сайте ведомства.', 'title': 'Мид: запад не реагирует на угрозы боевиков вывозу сирийского химоружия', 'sentences': ['Попытки привлечь запад к взаимодействию в борьбе с угрозами от боевиков в отношении вывоза химоружия в сирии не получили адекватной реакции, заявили во вторник в мид рф.', '\"к сожалению, наши попытки привлечь западные страны к реальному взаимодействию с целью нивелирования исходящих со стороны незаконных вооруженных формирований угроз в отношении операции по вывозу компонентов химоружия (из сирии) так и не получили адекватной реакции.', 'В частности, не было поддержано наше предложение принять на этот счет специальное заявление председателя совета безопасности оон\", — говорится в комментарии мид рф, размещенном на сайте ведомства.'], 'oracle_sentences': [0], 'oracle_summary': 'Попытки привлечь запад к взаимодействию в борьбе с угрозами от боевиков в отношении вывоза химоружия в сирии не получили адекватной реакции, заявили во вторник в мид рф.'}]}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "healthy-partition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 11, 50, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['inputs'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eleven-country",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 11])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['inputs'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "polished-blackjack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 11])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['inputs'][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-ebony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wanted-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "\n",
    "class SentenceEncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3, bidirectional=True):\n",
    "        super(SentenceEncoderRNN, self).__init__()\n",
    "\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        assert hidden_size % num_directions == 0\n",
    "        hidden_size = hidden_size // num_directions\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.embedding_layer = nn.Linear(input_size, embedding_dim)\n",
    "        self.rnn_layer = nn.LSTM(embedding_dim, hidden_size, n_layers, dropout=dropout, bidirectional=bidirectional, batch_first=True)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        embedded = self.embedding_layer(inputs)\n",
    "        outputs, _ = self.rnn_layer(embedded, hidden)\n",
    "        sentences_embeddings = torch.mean(outputs, 1)\n",
    "        return sentences_embeddings\n",
    "\n",
    "class SentenceTaggerRNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 token_embedding_dim=256,\n",
    "                 sentence_encoder_hidden_size=256,\n",
    "                 hidden_size=256,\n",
    "                 bidirectional=True,\n",
    "                 sentence_encoder_n_layers=2,\n",
    "                 sentence_encoder_dropout=0.3,\n",
    "                 sentence_encoder_bidirectional=True,\n",
    "                 n_layers=1,\n",
    "                 dropout=0.3):\n",
    "        super(SentenceTaggerRNN, self).__init__()\n",
    "\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        assert hidden_size % num_directions == 0\n",
    "        hidden_size = hidden_size // num_directions\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.sentence_encoder = SentenceEncoderRNN(vocabulary_size, token_embedding_dim,\n",
    "                                                   sentence_encoder_hidden_size, sentence_encoder_n_layers, \n",
    "                                                   sentence_encoder_dropout, sentence_encoder_bidirectional)\n",
    "        self.rnn_layer = nn.LSTM(sentence_encoder_hidden_size, hidden_size, n_layers, dropout=dropout,\n",
    "                           bidirectional=bidirectional, batch_first=True)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        self.content_linear_layer = nn.Linear(hidden_size * 2, 1)\n",
    "        self.document_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.salience_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.tanh_layer = nn.Tanh()\n",
    "        \n",
    "        self.output_bias = nn.Parameter(torch.ones(1))\n",
    "        self.abs_pos_emb = nn.Embedding(30, 1)\n",
    "        self.rel_pos_emb = nn.Embedding(6, 1)\n",
    "        self.novelty_tanh_layer = nn.Tanh()\n",
    "        self.novelty_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        embeddings_input = inputs[0]\n",
    "        abs_pos_input = inputs[1]\n",
    "        rel_pos_input = inputs[2]\n",
    "        batch_size = embeddings_input.size(0)\n",
    "        sentences_count = embeddings_input.size(1)\n",
    "        tokens_count = embeddings_input.size(2)\n",
    "        emb_size = embeddings_input.size(3)\n",
    "        embeddings_input = embeddings_input.reshape(-1, tokens_count, emb_size)\n",
    "        embedded_sentences = self.sentence_encoder(embeddings_input)\n",
    "        embedded_sentences = embedded_sentences.reshape(batch_size, sentences_count, -1)\n",
    "        outputs, _ = self.rnn_layer(embedded_sentences, hidden)\n",
    "        outputs = self.dropout_layer(outputs) # h [32, 30, 256]\n",
    "        document_embedding = self.tanh_layer(self.document_linear_layer(torch.mean(outputs, 1))) # [32, 256]\n",
    "        content = self.content_linear_layer(outputs).squeeze(2)\n",
    "        # self.salience_linear_layer(document_embedding).unsqueeze(2) [32, 256, 1]\n",
    "        # [32, 30, 256] * [32, 256, 1] -> [32, 30]\n",
    "        salience = torch.bmm(outputs, self.salience_linear_layer(document_embedding).unsqueeze(2)).squeeze(2)\n",
    "        rel_pos_embedding = self.rel_pos_emb(rel_pos_input).squeeze()\n",
    "        abs_pos_embedding = self.abs_pos_emb(abs_pos_input).squeeze()\n",
    "        pred_wo_summary = content + salience + self.output_bias + rel_pos_embedding + abs_pos_embedding # [32, 30]\n",
    "        \n",
    "        pred_summary = pred_wo_summary.clone().detach()\n",
    "        \n",
    "        novelty_vector = torch.zeros((batch_size, sentences_count), dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "        sliding_summary_first_element = torch.zeros((batch_size, self.hidden_size * 2), dtype=torch.float32, device=\"cuda\")\n",
    "        sliding_summary = torch.zeros((batch_size, sentences_count, self.hidden_size * 2), dtype=torch.float32, device=\"cuda\")\n",
    "        sliding_summary[:, 0, :] = sliding_summary_first_element.clone() \n",
    "\n",
    "        # for each sentence\n",
    "        for i in range(1, sentences_count):\n",
    "            # calc p[i-1]\n",
    "            weighted_sum = self.novelty_linear_layer(torch.tanh(sliding_summary[:, i - 1, :].clone().squeeze())).unsqueeze(2) # -> [32, 256, 1]\n",
    "            novelty_vector[:, i - 1] = torch.bmm(outputs[:, i - 1, :].clone().unsqueeze(1),  weighted_sum).squeeze() # [32]\n",
    "            pred_summary[:, i - 1] = pred_summary[:, i - 1].clone()  - novelty_vector[:, i - 1].clone()  \n",
    "            \n",
    "            # calc sliding_summary\n",
    "            final_s = sliding_summary_first_element.clone().detach()\n",
    "            for j in range(i):\n",
    "                final_s += torch.matmul(pred_summary[:, j].clone(), outputs[:, j, :].clone().squeeze()) # [32, 256]\n",
    "            sliding_summary[:, i, :] = final_s.clone()\n",
    "                  \n",
    "        return pred_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "realistic-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "def train_model(model, train_records, val_records, tokenizer, embeddings, batch_size=32,\n",
    "                epochs_count=10, loss_every_nsteps=16, lr=0.001, device_name=\"cuda\"):\n",
    "    params_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Trainable params: {}\".format(params_count))\n",
    "    device = torch.device(device_name)\n",
    "    model = model.to(device)\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_function = nn.BCEWithLogitsLoss().to(device)\n",
    "    for epoch in range(epochs_count):\n",
    "        for step, batch in enumerate(BatchIterator(train_records, batch_size, tokenizer, embeddings, device=device)):\n",
    "            model.train()\n",
    "            logits = model(batch[\"inputs\"]) # Прямой проход\n",
    "            loss = loss_function(logits, batch[\"outputs\"]) # Подсчёт ошибки\n",
    "            loss.backward() # Подсчёт градиентов dL/dw\n",
    "            optimizer.step() # Градиентный спуск или его модификации (в данном случае Adam)\n",
    "            optimizer.zero_grad() # Зануление градиентов, чтобы их спокойно менять на следующей итерации\n",
    "            total_loss += loss.item()\n",
    "            if step % loss_every_nsteps == 0 and step != 0:\n",
    "                val_total_loss = 0\n",
    "                val_batch_count = 0\n",
    "                model.eval()\n",
    "#                 for _, val_batch in enumerate(BatchIterator(val_records, vocabulary, batch_size, bpe_processor, device=device)):\n",
    "#                     logits = model(val_batch[\"inputs\"]) # Прямой проход\n",
    "#                     val_total_loss += loss_function(logits, val_batch[\"outputs\"]) # Подсчёт ошибки\n",
    "#                     val_batch_count += 1\n",
    "#                 avg_val_loss = val_total_loss/val_batch_count\n",
    "#                 print(\"Epoch = {}, Avg Train Loss = {:.4f}, Avg val loss = {:.4f}, Time = {:.2f}s\".format(epoch, total_loss / loss_every_nsteps, avg_val_loss, time.time() - start_time))\n",
    "                print(\"Epoch = {}, Avg Train Loss = {:.4f}, Time = {:.2f}s\".format(epoch, total_loss / loss_every_nsteps, time.time() - start_time))\n",
    "                total_loss = 0\n",
    "                start_time = time.time()\n",
    "        total_loss = 0\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-inflation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksenya/anaconda3/envs/nlp_project/lib/python3.6/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 1580326\n",
      "Epoch = 0, Avg Train Loss = 1.2350, Time = 905.25s\n",
      "Epoch = 0, Avg Train Loss = 0.9494, Time = 776.92s\n",
      "Epoch = 0, Avg Train Loss = 0.9191, Time = 767.12s\n",
      "Epoch = 0, Avg Train Loss = 0.8978, Time = 752.85s\n",
      "Epoch = 0, Avg Train Loss = 0.8994, Time = 777.80s\n",
      "Epoch = 0, Avg Train Loss = 0.8790, Time = 749.86s\n",
      "Epoch = 0, Avg Train Loss = 0.9475, Time = 796.74s\n",
      "Epoch = 0, Avg Train Loss = 0.8996, Time = 783.21s\n",
      "Epoch = 0, Avg Train Loss = 0.8862, Time = 801.85s\n",
      "Epoch = 0, Avg Train Loss = 0.8643, Time = 756.11s\n",
      "Epoch = 0, Avg Train Loss = 0.8750, Time = 739.63s\n",
      "Epoch = 0, Avg Train Loss = 0.8646, Time = 775.75s\n",
      "Epoch = 0, Avg Train Loss = 0.8181, Time = 765.45s\n",
      "Epoch = 0, Avg Train Loss = 0.7215, Time = 736.95s\n",
      "Epoch = 0, Avg Train Loss = 0.6706, Time = 742.47s\n",
      "Epoch = 0, Avg Train Loss = 0.2816, Time = 764.29s\n",
      "Epoch = 0, Avg Train Loss = 0.2229, Time = 783.32s\n",
      "Epoch = 0, Avg Train Loss = 0.1941, Time = 791.25s\n",
      "Epoch = 0, Avg Train Loss = 0.1908, Time = 751.35s\n",
      "Epoch = 0, Avg Train Loss = 0.1683, Time = 753.52s\n",
      "Epoch = 0, Avg Train Loss = 0.1697, Time = 780.19s\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTaggerRNN(768)\n",
    "train_model(model, all_train_data, all_test_data, tokenizer, embeddings, device_name=\"cuda\", batch_size=32, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-basic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "corporate-departure",
   "metadata": {},
   "source": [
    "Уменьшили количество параметров за счет предобученных эмбеддингов, однако runtime значительно увеличился"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-pattern",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-probability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
