{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Morphology.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2aLdk7uthUK"
      },
      "source": [
        "# Морфология\n",
        "В этом ноутбуке описана подготовка данных для задачи POS-tagging. А также пара простых моделей на keras, решающих данную задачу. Оригинальная задача и ноутбук есть в контесте: https://www.kaggle.com/c/rupos2018/overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIgCu7tjthUx"
      },
      "source": [
        "## Часть 1. Загрузка корпуса\n",
        "Здесь мы прочитаем корпуса из csv и разложим их по спискам."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE_N3OBvthUy"
      },
      "source": [
        "# для совместимости со вторым питоном\n",
        "from __future__ import print_function\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ad156ee50218601b689e546907d0ce3109e155bd",
        "id": "4Wz6nbWVthUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab53762-4d43-462a-dcc7-5ce564354651"
      },
      "source": [
        "# Имена файлов с данными.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oubg7iXswups",
        "outputId": "44748c28-ca54-4436-805b-f5d7b1b2f7ec"
      },
      "source": [
        "!ls drive/MyDrive/NLP/ft_native_300_ru_wiki_lenta_lower_case.vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/MyDrive/NLP/ft_native_300_ru_wiki_lenta_lower_case.vec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhpF_oM7oZbu"
      },
      "source": [
        "TRAIN_FILENAME = \"drive/MyDrive/NLP/pos_tagging/train.csv\"\n",
        "TEST_FILENAME = \"drive/MyDrive/NLP/pos_tagging/test.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "fdbea001cf6b2aa7b763b4836050dc4fdabb6457",
        "id": "l_MaFhlRthU0"
      },
      "source": [
        "# Считывание файлов.\n",
        "from collections import namedtuple\n",
        "WordForm = namedtuple(\"WordForm\", \"word pos gram\")\n",
        "\n",
        "def get_sentences(filename, is_train):\n",
        "    sentences = []\n",
        "    with io.open(filename, \"r\", encoding='utf-8') as r:\n",
        "        # Пропускаем заголовок\n",
        "        next(r)\n",
        "        sentence = [] # будем заполнять список предложений\n",
        "        for line in r:\n",
        "            # предложения отделены по '\\n'\n",
        "            if len(line.strip()) == 0:\n",
        "                if len(sentence) == 0:\n",
        "                    continue\n",
        "                sentences.append(sentence)\n",
        "                sentence = []\n",
        "                continue\n",
        "            if is_train:\n",
        "                # Формат: индекс\\tномер_в_предложении\\tсловоформа\\tPOS#Грамемы\n",
        "                word = line.strip().split(\"\\t\")[2]\n",
        "                pos = line.strip().split(\"\\t\")[3].split(\"#\")[0]\n",
        "                gram = line.strip().split(\"\\t\")[3].split(\"#\")[1]\n",
        "                sentence.append(WordForm(word, pos, gram))\n",
        "            else:\n",
        "                word = line.strip().split(\"\\t\")[2]\n",
        "                sentence.append(word)\n",
        "        if len(sentence) != 0:\n",
        "            sentences.append(sentence)\n",
        "    return sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "fe4e1691bc5ef95abc711c5f403b27b897647878",
        "scrolled": true,
        "id": "MK4IHdKsthU0"
      },
      "source": [
        "train = get_sentences(TRAIN_FILENAME, True)\n",
        "test = get_sentences(TEST_FILENAME, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgEReVxWpg8J",
        "outputId": "f2740a82-a145-456b-f2dc-a5c3380e7feb"
      },
      "source": [
        "train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordForm(word='А', pos='CONJ', gram='_'),\n",
              " WordForm(word='ведь', pos='PART', gram='_'),\n",
              " WordForm(word='для', pos='ADP', gram='_'),\n",
              " WordForm(word='конкретных', pos='ADJ', gram='Case=Gen|Degree=Pos|Number=Plur'),\n",
              " WordForm(word='изделий', pos='NOUN', gram='Animacy=Inan|Case=Gen|Gender=Neut|Number=Plur'),\n",
              " WordForm(word='зачастую', pos='ADV', gram='Degree=Pos'),\n",
              " WordForm(word='нужен', pos='ADJ', gram='Degree=Pos|Gender=Masc|Number=Sing|Variant=Brev'),\n",
              " WordForm(word='монокристалл', pos='NOUN', gram='Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing'),\n",
              " WordForm(word='не', pos='PART', gram='_'),\n",
              " WordForm(word='только', pos='PART', gram='_'),\n",
              " WordForm(word='крупный', pos='ADJ', gram='Case=Nom|Degree=Pos|Gender=Masc|Number=Sing'),\n",
              " WordForm(word=',', pos='PUNCT', gram='_'),\n",
              " WordForm(word='но', pos='CONJ', gram='_'),\n",
              " WordForm(word='и', pos='PART', gram='_'),\n",
              " WordForm(word='заданной', pos='VERB', gram='Aspect=Perf|Case=Gen|Gender=Fem|Number=Sing|Tense=Past|VerbForm=Part|Voice=Pass'),\n",
              " WordForm(word='формы', pos='NOUN', gram='Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing'),\n",
              " WordForm(word=',', pos='PUNCT', gram='_'),\n",
              " WordForm(word='например', pos='ADV', gram='Degree=Pos'),\n",
              " WordForm(word='\"', pos='PUNCT', gram='_'),\n",
              " WordForm(word='стакан', pos='NOUN', gram='Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing'),\n",
              " WordForm(word='\"', pos='PUNCT', gram='_'),\n",
              " WordForm(word=',', pos='PUNCT', gram='_'),\n",
              " WordForm(word='\"', pos='PUNCT', gram='_'),\n",
              " WordForm(word='тройник', pos='NOUN', gram='Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing'),\n",
              " WordForm(word='\"', pos='PUNCT', gram='_'),\n",
              " WordForm(word='(', pos='PUNCT', gram='_'),\n",
              " WordForm(word='элемент', pos='NOUN', gram='Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing'),\n",
              " WordForm(word='трубопровода', pos='NOUN', gram='Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing'),\n",
              " WordForm(word=')', pos='PUNCT', gram='_'),\n",
              " WordForm(word='или', pos='CONJ', gram='_'),\n",
              " WordForm(word='еще', pos='ADV', gram='Degree=Pos'),\n",
              " WordForm(word='сложнее', pos='ADJ', gram='Degree=Cmp'),\n",
              " WordForm(word='.', pos='PUNCT', gram='_')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OXasxInthU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f32e5a-4722-4e4a-ea2e-4625276baa93"
      },
      "source": [
        "# Выведем, что получилось\n",
        "for wordform in train[0][:10]:\n",
        "    print(wordform.word, '\\t', wordform.pos, '\\t', wordform.gram)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "А \t CONJ \t _\n",
            "ведь \t PART \t _\n",
            "для \t ADP \t _\n",
            "конкретных \t ADJ \t Case=Gen|Degree=Pos|Number=Plur\n",
            "изделий \t NOUN \t Animacy=Inan|Case=Gen|Gender=Neut|Number=Plur\n",
            "зачастую \t ADV \t Degree=Pos\n",
            "нужен \t ADJ \t Degree=Pos|Gender=Masc|Number=Sing|Variant=Brev\n",
            "монокристалл \t NOUN \t Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
            "не \t PART \t _\n",
            "только \t PART \t _\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHOyPoDvthU6"
      },
      "source": [
        "Для простоты далее будем использовать токены слов и POS-теги. Но чтобы определять грамматические значения нужно еще провести некоторые манипуляции с данными, описанные в оригинальном ноутубке. Мы же ограничимся только определением частей речи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf8hf8KuthU6"
      },
      "source": [
        "## Часть 2. Подготовка эмбеддингов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8o74UzLthU6"
      },
      "source": [
        "Обычно в качестве признаков для обучения сеток используются словные эмбеддинги. Для этого можно скачать предобученные и сохранить их в матрицу, где в расположатся векторы эмбеддингах по индексам, соответсвующих слов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7vf5ATuthU6"
      },
      "source": [
        "#запомним все уникальные слова и POS-теги в корпусе\n",
        "word_set = set()\n",
        "pos_set = set()\n",
        "for sent in train:\n",
        "    for wordform in sent:\n",
        "        word_set.add(wordform.word.lower())\n",
        "        pos_set.add(wordform.pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puJCyy_PthU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dccb8c05-a381-4f9a-aa7f-dfe42cbb95ff"
      },
      "source": [
        "for word in list(word_set)[:10]: \n",
        "    print(word, end=', ')\n",
        "print()\n",
        "print(pos_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ведрами, оснащенного, идеалу, воровстве, крупный, упрекнуть, 2269, конкретными, оккупационных, нравятся, \n",
            "{'PRON', 'INTJ', 'PUNCT', 'X', 'ADV', 'ADP', 'NUM', 'NOUN', 'PART', 'CONJ', 'SYM', 'AUX', 'ADJ', 'PROPN', 'DET', 'SCONJ', 'VERB'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4cNwbJFthU7"
      },
      "source": [
        "#Загрузите эмбеддинги c https://nlp.stanford.edu/projects/glove/ или другие, которые вам нравятся и пропишите путь к ним\n",
        "import numpy as np\n",
        "\n",
        "word_embeddings_path = 'drive/MyDrive/NLP/ft_native_300_ru_wiki_lenta_lower_case.vec'\n",
        "word2idx = {}\n",
        "word_embeddings = []\n",
        "embedding_size = 300\n",
        "#Загружаем эмбеддинги\n",
        "with io.open(word_embeddings_path, 'r', encoding=\"utf-8\") as f_em:\n",
        "    for line in f_em:\n",
        "        split = line.strip().split(\" \")\n",
        "        # Совсем короткие строки пропускаем\n",
        "        if len(split) <= 2:\n",
        "            continue\n",
        "        # Встретив первую подходящую строку, фиксируем размер эмбеддингов\n",
        "        if embedding_size is None:\n",
        "            embedding_size = len(split) - 1\n",
        "            # Также нициализируем эмбеддинги для паддингов и неизвестных слов\n",
        "            word2idx[\"PADDING_TOKEN\"] = len(word2idx)\n",
        "            word_embeddings.append(np.zeros(embedding_size))\n",
        "\n",
        "            word2idx[\"UNKNOWN_TOKEN\"] = len(word2idx)\n",
        "            word_embeddings.append(np.random.uniform(-0.25, 0.25, embedding_size))\n",
        "        # После этого все эмбеддинги должны быть одинаковой длины\n",
        "        if len(split) - 1 != embedding_size:\n",
        "            continue\n",
        "            \n",
        "        # Если слова нет в корпусе, то не будем для него запоминать эмбеддинг        \n",
        "        if (split[0] not in word_set):\n",
        "            continue\n",
        "        \n",
        "        word_embeddings.append(np.asarray(split[1:], dtype='float32'))\n",
        "        word2idx[split[0]] = len(word2idx)\n",
        "\n",
        "word_embeddings = np.array(word_embeddings, dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_khigyzthU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "063cf5dc-e962-4ad9-bcc4-a860fa179c08"
      },
      "source": [
        "len(word_set & set(word2idx.keys()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92618"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeP1PvZjthU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13049ab-8fd0-4559-c1a6-67611eeb0417"
      },
      "source": [
        "len(word_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98880"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxp0jfRL0Kww",
        "outputId": "ff3e6326-b771-47b5-bb70-2ab1ce679eb1"
      },
      "source": [
        "len(word2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92618"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEuyw5kZLKPk",
        "outputId": "2ad264bf-f795-4f06-bf00-e1b1b04d3bb8"
      },
      "source": [
        "word_embeddings.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(92618, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRzOa-DGthU8"
      },
      "source": [
        "Как-то эмбеддинги не сильно подходят для данного корпуса поэтому, просто инициализируем рандмно матрицу эмбеддингов при определении сетки. Вам же предлагается все-таки поискать подходящие эмбеддинги и использовать их при обучении."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXTTW2_qthU9"
      },
      "source": [
        "## Часть 3. Подготовка данных\n",
        "Теперь нам остается только пронумеровать все слова и POS-теги и можно переходить к обучению сеток."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh5eO3iGthU9"
      },
      "source": [
        "word_to_index = {'PAD' : 0, 'UNK' : 1}\n",
        "for word in word_set:\n",
        "    word_to_index[word] = len(word_to_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OPaZ6tethU9"
      },
      "source": [
        "pos_to_index = {}\n",
        "index_to_pos = {}\n",
        "for pos in pos_set:\n",
        "    pos_to_index[pos] = len(pos_to_index)\n",
        "    index_to_pos[len(index_to_pos)] = pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHwJMKAIthU9"
      },
      "source": [
        "# для полносвязной сетки просто положим все индексы в один список\n",
        "data_X = []\n",
        "data_Y = []\n",
        "for sent in train:\n",
        "    for wordform in sent:\n",
        "        data_X.append(word_to_index[wordform.word.lower()])\n",
        "        data_Y.append(pos_to_index[wordform.pos])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XiubstMthU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32fde025-2538-4756-fcdb-68613f45b1fa"
      },
      "source": [
        "print(data_X[:10])\n",
        "print(data_Y[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[20541, 41209, 15563, 84569, 28007, 10201, 95436, 69436, 47276, 26882]\n",
            "[9, 8, 5, 12, 7, 4, 12, 7, 8, 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKCpevsqthU-"
      },
      "source": [
        "## Часть 4. Полносвязная сеть\n",
        "Самой простой моделью является обычный перцептрон. На вход сетки будем подавать просто эмдеддинг каждого слова, на выходе ожидать распредедение вероятностей по тегам. В качестве фреймворка достаточно будет использовать keras и его Sequential модель (https://keras.io/models/sequential/), в которую слои добавляются последовательно, с помощью метода `add`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5x3JrebthU-"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Activation, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBX8eR_MthU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1522bd7c-79bf-464d-bcd6-a07ef72d2671"
      },
      "source": [
        "model = Sequential()\n",
        "# на самом деле на вход сетки будет добавляться индекс слова, а слой эмбеддинга будет возвращать для него вектор\n",
        "model.add(Embedding(input_length=1, input_dim=len(word_to_index), output_dim=50, embeddings_initializer='random_uniform',\n",
        "                    trainable=False)) # матрицу эмбеддингов просто инициализируем нормальным распределением и отключим обучение\n",
        "# далее нам нужно схлопнуть трехмерный тензор с одной фиктивной размерностью в двумерный\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100)) # основной полносвязный слой\n",
        "model.add(Activation('relu')) # для приличия добавим функцию активации\n",
        "model.add(Dense(len(pos_to_index))) # выходной слой тоже полносвязный размерности по кол-ву тегов\n",
        "model.add(Activation('softmax')) # ну и в конце делаем softmax, чтобы получить распределение\n",
        "model.summary() # вывод получившейся модели"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 1, 50)             4944100   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               5100      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 17)                1717      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 4,950,917\n",
            "Trainable params: 6,817\n",
            "Non-trainable params: 4,944,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2iSdm6OthU_"
      },
      "source": [
        "# компилируем модель\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnZctr02thU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f89bb0-66c8-4e62-c461-874f3b1f1654"
      },
      "source": [
        "# и обучаем\n",
        "model.fit(np.array(data_X), np.array(data_Y), epochs=5, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "3324/3324 [==============================] - 5s 2ms/step - loss: 1.1216 - accuracy: 0.6195\n",
            "Epoch 2/5\n",
            "3324/3324 [==============================] - 6s 2ms/step - loss: 1.0096 - accuracy: 0.6475\n",
            "Epoch 3/5\n",
            "3324/3324 [==============================] - 5s 2ms/step - loss: 0.9453 - accuracy: 0.6654\n",
            "Epoch 4/5\n",
            "3324/3324 [==============================] - 6s 2ms/step - loss: 0.9054 - accuracy: 0.6778\n",
            "Epoch 5/5\n",
            "3324/3324 [==============================] - 6s 2ms/step - loss: 0.8776 - accuracy: 0.6851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff7c7957710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPjFyOCWthVB"
      },
      "source": [
        "Проверка обученности модели остается за вами. Этот пример лишь для того, чтобы показать как собрать сетку и скормить ей данные."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK2-imwVthVB"
      },
      "source": [
        "## Часть 5. Рекуррентая сеть."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvC_ZFMlthVC"
      },
      "source": [
        "Далее рассмотрим более приближенную к SOTA модель. Ей является рекуррентая сеть, которая принимает эмбеддинги слов в предложении и генерирует для них распределение вероятностей. Основным отличием от прошлой в том, что теперь мы будем использовать соседние слова как раз за счет рекуррентого слоя. Для этой модели мы уже будем использовать функциональный способ задания модели все того же кераса (https://keras.io/models/model/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzLHDcyLthVC"
      },
      "source": [
        "from keras.layers import LSTM, TimeDistributed,Bidirectional, Input\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wknB8jbAthVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c180705-3585-46d6-a75c-82908985df45"
      },
      "source": [
        "# В начале задается входной слой, в котором мы укажем входную размерность. \n",
        "# Это будет None, т.к. мы заранее не знаем, какой будет длина каждого предложения \n",
        "input_layer = Input(shape=(None,), name='input')\n",
        "# Далее идет все тот же слой эмеддинга, которому мы на вход подаем предыдущий слой (в этом и суть functional APO)\n",
        "embeddings_layer = Embedding(input_dim=len(word_to_index), output_dim=50, \n",
        "                             trainable=False, embeddings_initializer='random_uniform',\n",
        "                             name='embedding')(input_layer)\n",
        "# Итак, основным слоем здесь будет двусторонний LSTM, который будет возвращать вектор для каждого слова (return_sequences=True) \n",
        "blstm_layer = Bidirectional(LSTM(100, return_sequences=True), name='blstm')(embeddings_layer)\n",
        "# Аналогично т.к. у нас здесь вектора для каждого слоя, то и полносвязный слой должен применяться для каждого слоя \n",
        "# по-отдельности. Поэтому полносвязный слой оборачивается в  TimeDistributed\n",
        "result_layer = TimeDistributed(Dense(len(pos_to_index), activation='softmax', name='result'))(blstm_layer)\n",
        "# собственно определяем модель входными и выходными слоями\n",
        "model = Model(inputs=[input_layer], outputs=result_layer)\n",
        "# компилируем\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# выводим архитектуру\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, None, 50)          4944100   \n",
            "_________________________________________________________________\n",
            "blstm (Bidirectional)        (None, None, 200)         120800    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, None, 17)          3417      \n",
            "=================================================================\n",
            "Total params: 5,068,317\n",
            "Trainable params: 124,217\n",
            "Non-trainable params: 4,944,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbUCNAAVthVD"
      },
      "source": [
        "Далее нам нужно было бы распределить слова по предложениям, распределить по группам по длине, выравнить предложения по длине в одной групе, заполнив недостающие слова паддингами. Но это довольно неприятный процесс, а мне просто хочется запустить сетку и проверить, что она вообще работает, что сошлись все разверности. Поэтому просто раскидаем по 10 слов с помощью `numpy.reshape`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d8lkn1tthVD"
      },
      "source": [
        "rnnX = np.reshape(data_X[:850000], (-1,10))\n",
        "rnnY = np.reshape(data_Y[:850000], (-1,10,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol7jZI2OuX0N"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPvJxJDwthVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1af59fa-d165-46af-99e4-6c4308aeee21"
      },
      "source": [
        "np.shape(rnnX)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ5KBBGHthVE"
      },
      "source": [
        "Ну и проверим, что оно вообще работает."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IbpZehgthVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a49751-ba7d-4bd7-e7fa-96b4b5d527b7"
      },
      "source": [
        "model.fit(rnnX, rnnY, epochs=1, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "333/333 [==============================] - 26s 77ms/step - loss: 2.0785 - accuracy: 0.3580\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff7c771c828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml67pXR1thVH"
      },
      "source": [
        "## Часть 6. Задание\n",
        "В качестве упражения предлагается довести до ума обучения второй модели: распределить слова по предложениям, написать тестирование модели и собственно посмотреть как оно обучилось. Тестировать предлагаю на последней 1000 предложений, обучать - на остальном. Кто уверен в своих желаниях, то может решить оригинальную задачу: предсказывать также грамматические категории. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWtDPFkYyq-d"
      },
      "source": [
        "pos_to_index['PAD'] = len(pos_to_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bl1g7QOu1oP"
      },
      "source": [
        "# для RNN сетки соберем данные по предложениям\n",
        "sent_len = 30\n",
        "data_X = []\n",
        "data_Y = []\n",
        "for sent in train:\n",
        "  x_sent_ind = []\n",
        "  y_sent_ind = []\n",
        "  for wordform in sent:\n",
        "      x_sent_ind.append(word_to_index[wordform.word.lower()])\n",
        "      y_sent_ind.append(pos_to_index[wordform.pos])\n",
        "  # if small then padd\n",
        "  if len(x_sent_ind) <= sent_len:\n",
        "    x_sent_ind.extend([word_to_index['PAD']]*(sent_len-len(x_sent_ind)))\n",
        "    y_sent_ind.extend([pos_to_index['PAD']]*(sent_len-len(y_sent_ind)))\n",
        "    data_X.append(x_sent_ind)\n",
        "    data_Y.append(y_sent_ind)\n",
        "  # if big then cut\n",
        "  else:\n",
        "    for i in range(len(x_sent_ind) - sent_len):\n",
        "      data_X.append(x_sent_ind[i:sent_len+i])\n",
        "      data_Y.append(y_sent_ind[i:sent_len+i]) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4XMh1201BYx"
      },
      "source": [
        "data_Y = np.array(data_Y)\n",
        "data_Y = data_Y.reshape((data_Y.shape[0], data_Y.shape[1], 1))\n",
        "data_X = np.array(data_X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7Etq5Ehw41C",
        "outputId": "281409e9-a00b-4f32-af96-295668c1f8d0"
      },
      "source": [
        "# В начале задается входной слой, в котором мы укажем входную размерность. \n",
        "# Это будет None, т.к. мы заранее не знаем, какой будет длина каждого предложения \n",
        "input_layer = Input(shape=(sent_len,), name='input')\n",
        "# Далее идет все тот же слой эмеддинга, которому мы на вход подаем предыдущий слой (в этом и суть functional APO)\n",
        "embeddings_layer = Embedding(input_dim=len(word_to_index), output_dim=50, \n",
        "                             trainable=False, embeddings_initializer='random_uniform',\n",
        "                             name='embedding')(input_layer)\n",
        "# Итак, основным слоем здесь будет двусторонний LSTM, который будет возвращать вектор для каждого слова (return_sequences=True) \n",
        "blstm_layer = Bidirectional(LSTM(100, return_sequences=True), name='blstm')(embeddings_layer)\n",
        "# Аналогично т.к. у нас здесь вектора для каждого слоя, то и полносвязный слой должен применяться для каждого слоя \n",
        "# по-отдельности. Поэтому полносвязный слой оборачивается в  TimeDistributed\n",
        "hidden_layer = TimeDistributed(Dense(64, activation='relu', name='hidden'))(blstm_layer)\n",
        "result_layer = TimeDistributed(Dense(len(pos_to_index), activation='softmax', name='result'))(hidden_layer)\n",
        "# собственно определяем модель входными и выходными слоями\n",
        "model = Model(inputs=[input_layer], outputs=result_layer)\n",
        "# компилируем\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# выводим архитектуру\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 30, 50)            4944100   \n",
            "_________________________________________________________________\n",
            "blstm (Bidirectional)        (None, 30, 200)           120800    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 30, 64)            12864     \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 30, 18)            1170      \n",
            "=================================================================\n",
            "Total params: 5,078,934\n",
            "Trainable params: 134,834\n",
            "Non-trainable params: 4,944,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "arwgDmq707Q5",
        "outputId": "8fdbb54f-0c3e-44a9-de95-b1c468ccf489"
      },
      "source": [
        "model.fit(data_X, data_Y, epochs=5, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "360/360 [==============================] - 78s 217ms/step - loss: 1.6183 - accuracy: 0.4936\n",
            "Epoch 2/5\n",
            "360/360 [==============================] - 81s 226ms/step - loss: 1.1624 - accuracy: 0.6296\n",
            "Epoch 3/5\n",
            "105/360 [=======>......................] - ETA: 57s - loss: 1.0817 - accuracy: 0.6469"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-0071d8bb7b63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm846pyFyDfk"
      },
      "source": [
        "Add embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDW5iWbxydxM",
        "outputId": "cfb0d775-9a86-4e04-8e01-57dff9f841d2"
      },
      "source": [
        "word_embeddings.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(92618, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgB1gpg9Ksik",
        "outputId": "109c37f5-ca9d-46d1-9e30-c73d33b2a62d"
      },
      "source": [
        "len(word2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92618"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SakLKZgZCPNb",
        "outputId": "2717d90d-6b80-49be-93c2-b533d7e82b72"
      },
      "source": [
        "len(word_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98880"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNLpK07BEWut"
      },
      "source": [
        "unknown_tok = word_set - set(word2idx.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFoLImNpE5V4"
      },
      "source": [
        "if \"UNKNOWN_TOKEN\" not in word2idx:\n",
        "  word2idx[\"UNKNOWN_TOKEN\"] = len(word2idx)\n",
        "  unknown_emb = np.random.uniform(-0.25, 0.25, embedding_size)\n",
        "  word_embeddings = np.vstack([word_embeddings, unknown_emb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6Fz1SURlR5d",
        "outputId": "ced40364-f6c3-4e9f-c174-7aea69119cb4"
      },
      "source": [
        "len(word2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92619"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPQ-luBvlTlr",
        "outputId": "a63774d1-99a9-4576-c558-6f0d40ff32b2"
      },
      "source": [
        "word_embeddings.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(92619, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAgZXrghzJck"
      },
      "source": [
        "for word in unknown_tok:\n",
        "    word2idx[word] = word2idx[\"UNKNOWN_TOKEN\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zp1-pd1Hjgv"
      },
      "source": [
        "if \"PADDING_TOKEN\" not in word2idx:\n",
        "  word2idx[\"PADDING_TOKEN\"] = word2idx[\"UNKNOWN_TOKEN\"] + 1\n",
        "  word_embeddings = np.vstack([word_embeddings, np.zeros(embedding_size)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NY1Tmurkxr9",
        "outputId": "924050c7-3ef5-41b5-9c4a-de739794710e"
      },
      "source": [
        "word2idx['PADDING_TOKEN']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92619"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLliBzZ1HQ8c"
      },
      "source": [
        "# для RNN сетки соберем данные по предложениям\n",
        "sent_len = 30\n",
        "data_X = []\n",
        "data_Y = []\n",
        "for sent in train:\n",
        "  x_sent_ind = []\n",
        "  y_sent_ind = []\n",
        "  for wordform in sent:\n",
        "      x_sent_ind.append(word2idx[wordform.word.lower()])\n",
        "      y_sent_ind.append(pos_to_index[wordform.pos])\n",
        "  # if small then padd\n",
        "  if len(x_sent_ind) <= sent_len:\n",
        "    x_sent_ind.extend([word2idx['PADDING_TOKEN']]*(sent_len-len(x_sent_ind)))\n",
        "    y_sent_ind.extend([pos_to_index['PAD']]*(sent_len-len(y_sent_ind)))\n",
        "    data_X.append(x_sent_ind)\n",
        "    data_Y.append(y_sent_ind)\n",
        "  # if big then cut\n",
        "  else:\n",
        "    for i in range(len(x_sent_ind) - sent_len):\n",
        "      data_X.append(x_sent_ind[i:sent_len+i])\n",
        "      data_Y.append(y_sent_ind[i:sent_len+i]) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EBZgLnXAyjY"
      },
      "source": [
        "data_Y = np.array(data_Y)\n",
        "data_Y = data_Y.reshape((data_Y.shape[0], data_Y.shape[1], 1))\n",
        "data_X = np.array(data_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNWr6pLnyGDD",
        "outputId": "26cae1a4-823a-4a9e-d593-3fe27a39dfc5"
      },
      "source": [
        "# В начале задается входной слой, в котором мы укажем входную размерность. \n",
        "# Это будет None, т.к. мы заранее не знаем, какой будет длина каждого предложения \n",
        "input_layer = Input(shape=(sent_len,), name='input')\n",
        "# Далее идет все тот же слой эмеддинга, которому мы на вход подаем предыдущий слой (в этом и суть functional APO)\n",
        "embeddings_layer = Embedding(input_dim=word_embeddings.shape[0], output_dim=300, \n",
        "                             trainable=False, weights=[word_embeddings],\n",
        "                             name='embedding')(input_layer)\n",
        "# Итак, основным слоем здесь будет двусторонний LSTM, который будет возвращать вектор для каждого слова (return_sequences=True) \n",
        "blstm_layer = Bidirectional(LSTM(100, return_sequences=True), name='blstm')(embeddings_layer)\n",
        "# Аналогично т.к. у нас здесь вектора для каждого слоя, то и полносвязный слой должен применяться для каждого слоя \n",
        "# по-отдельности. Поэтому полносвязный слой оборачивается в  TimeDistributed\n",
        "hidden_layer = TimeDistributed(Dense(64, activation='relu', name='hidden'))(blstm_layer)\n",
        "result_layer = TimeDistributed(Dense(len(pos_to_index), activation='softmax', name='result'))(hidden_layer)\n",
        "# собственно определяем модель входными и выходными слоями\n",
        "model = Model(inputs=[input_layer], outputs=result_layer)\n",
        "# компилируем\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# выводим архитектуру\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 30, 300)           27786000  \n",
            "_________________________________________________________________\n",
            "blstm (Bidirectional)        (None, 30, 200)           320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 30, 64)            12864     \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 30, 18)            1170      \n",
            "=================================================================\n",
            "Total params: 28,120,834\n",
            "Trainable params: 334,834\n",
            "Non-trainable params: 27,786,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPWfgJ_ty9pG",
        "outputId": "37cd7a7d-6183-4df9-be83-47c37f53a812"
      },
      "source": [
        "model.fit(data_X[:-1000], data_Y[:-1000], epochs=10, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "356/356 [==============================] - 102s 286ms/step - loss: 0.3433 - accuracy: 0.9017\n",
            "Epoch 2/10\n",
            "356/356 [==============================] - 102s 285ms/step - loss: 0.1159 - accuracy: 0.9638\n",
            "Epoch 3/10\n",
            "356/356 [==============================] - 101s 284ms/step - loss: 0.0855 - accuracy: 0.9734\n",
            "Epoch 4/10\n",
            "356/356 [==============================] - 102s 287ms/step - loss: 0.0680 - accuracy: 0.9791\n",
            "Epoch 5/10\n",
            "356/356 [==============================] - 103s 289ms/step - loss: 0.0567 - accuracy: 0.9828\n",
            "Epoch 6/10\n",
            "356/356 [==============================] - 102s 285ms/step - loss: 0.0484 - accuracy: 0.9855\n",
            "Epoch 7/10\n",
            "356/356 [==============================] - 101s 284ms/step - loss: 0.0419 - accuracy: 0.9875\n",
            "Epoch 8/10\n",
            "356/356 [==============================] - 101s 284ms/step - loss: 0.0372 - accuracy: 0.9890\n",
            "Epoch 9/10\n",
            "356/356 [==============================] - 101s 284ms/step - loss: 0.0330 - accuracy: 0.9903\n",
            "Epoch 10/10\n",
            "356/356 [==============================] - 101s 284ms/step - loss: 0.0297 - accuracy: 0.9913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7edac78be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw201Tq2NQj0"
      },
      "source": [
        "y_pred = model.predict(data_X[-1000:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqhIynTJsJgP",
        "outputId": "0ece5e35-2735-4a9b-eed5-35eab32006ea"
      },
      "source": [
        "np.reshape(data_Y[-1000:], (-1)).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhs-Gxjwr3JZ"
      },
      "source": [
        "y_pred_classes = []\n",
        "for i in range(y_pred.shape[0]):\n",
        "  for j in range(sent_len):\n",
        "    y_pred_classes.append(np.argmax(y_pred[i][j]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nce2CWSSrVj2",
        "outputId": "b0fb48ad-1566-4df0-aa79-ded9689de0c9"
      },
      "source": [
        "y_pred_classes = np.array(y_pred_classes)\n",
        "y_pred_classes.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPZS3SuirBRJ"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbitubienHzX",
        "outputId": "6bd8069b-e2d8-46f4-da15-1dfc58e365c4"
      },
      "source": [
        "print(classification_report(y_pred_classes, np.reshape(data_Y[-1000:], (-1))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.90      0.92       784\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.99      0.98      0.99      3987\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.95      0.93      0.94      1074\n",
            "           5       0.99      1.00      0.99      2077\n",
            "           6       0.98      0.98      0.98       439\n",
            "           7       0.99      0.98      0.99      5720\n",
            "           8       0.94      0.90      0.92       732\n",
            "           9       0.93      0.96      0.95       840\n",
            "          11       0.85      0.97      0.90       159\n",
            "          12       0.98      0.96      0.97      2459\n",
            "          13       0.90      0.97      0.93       683\n",
            "          14       0.92      0.97      0.94       564\n",
            "          15       0.96      0.97      0.96       520\n",
            "          16       0.97      0.97      0.97      2503\n",
            "          17       1.00      1.00      1.00      7458\n",
            "\n",
            "    accuracy                           0.98     30000\n",
            "   macro avg       0.84      0.85      0.84     30000\n",
            "weighted avg       0.98      0.98      0.98     30000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVf1EliRnX8H"
      },
      "source": [
        "Make embedding trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfOqqG4SnWog",
        "outputId": "452da2fc-b0a6-431a-cdca-4be06a13a59a"
      },
      "source": [
        "# В начале задается входной слой, в котором мы укажем входную размерность. \n",
        "# Это будет None, т.к. мы заранее не знаем, какой будет длина каждого предложения \n",
        "input_layer = Input(shape=(sent_len,), name='input')\n",
        "# Далее идет все тот же слой эмеддинга, которому мы на вход подаем предыдущий слой (в этом и суть functional APO)\n",
        "embeddings_layer = Embedding(input_dim=word_embeddings.shape[0], output_dim=300, \n",
        "                             trainable=True, weights=[word_embeddings],\n",
        "                             name='embedding')(input_layer)\n",
        "# Итак, основным слоем здесь будет двусторонний LSTM, который будет возвращать вектор для каждого слова (return_sequences=True) \n",
        "blstm_layer = Bidirectional(LSTM(100, return_sequences=True), name='blstm')(embeddings_layer)\n",
        "# Аналогично т.к. у нас здесь вектора для каждого слоя, то и полносвязный слой должен применяться для каждого слоя \n",
        "# по-отдельности. Поэтому полносвязный слой оборачивается в  TimeDistributed\n",
        "hidden_layer = TimeDistributed(Dense(64, activation='relu', name='hidden'))(blstm_layer)\n",
        "result_layer = TimeDistributed(Dense(len(pos_to_index), activation='softmax', name='result'))(hidden_layer)\n",
        "# собственно определяем модель входными и выходными слоями\n",
        "model = Model(inputs=[input_layer], outputs=result_layer)\n",
        "# компилируем\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# выводим архитектуру\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 30, 300)           27786000  \n",
            "_________________________________________________________________\n",
            "blstm (Bidirectional)        (None, 30, 200)           320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 30, 64)            12864     \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 30, 18)            1170      \n",
            "=================================================================\n",
            "Total params: 28,120,834\n",
            "Trainable params: 28,120,834\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyUmawPLnWuD",
        "outputId": "719b2c3c-26e9-4766-8575-3a378b1a10d5"
      },
      "source": [
        "model.fit(data_X[:-1000], data_Y[:-1000], epochs=10, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "356/356 [==============================] - 184s 516ms/step - loss: 0.3269 - accuracy: 0.9104\n",
            "Epoch 2/10\n",
            "356/356 [==============================] - 181s 508ms/step - loss: 0.0378 - accuracy: 0.9884\n",
            "Epoch 3/10\n",
            "356/356 [==============================] - 180s 505ms/step - loss: 0.0194 - accuracy: 0.9942\n",
            "Epoch 4/10\n",
            "356/356 [==============================] - 180s 506ms/step - loss: 0.0107 - accuracy: 0.9969\n",
            "Epoch 5/10\n",
            "356/356 [==============================] - 180s 507ms/step - loss: 0.0060 - accuracy: 0.9984\n",
            "Epoch 6/10\n",
            "356/356 [==============================] - 180s 506ms/step - loss: 0.0036 - accuracy: 0.9990\n",
            "Epoch 7/10\n",
            "356/356 [==============================] - 179s 502ms/step - loss: 0.0023 - accuracy: 0.9994\n",
            "Epoch 8/10\n",
            "356/356 [==============================] - 178s 501ms/step - loss: 0.0015 - accuracy: 0.9996\n",
            "Epoch 9/10\n",
            "356/356 [==============================] - 178s 501ms/step - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 10/10\n",
            "356/356 [==============================] - 179s 503ms/step - loss: 8.5088e-04 - accuracy: 0.9998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7e82909208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIVD2GEcn9k1"
      },
      "source": [
        "y_pred = model.predict(data_X[-1000:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNMFM5PCn91Y"
      },
      "source": [
        "y_pred_classes = []\n",
        "for i in range(y_pred.shape[0]):\n",
        "  for j in range(sent_len):\n",
        "    y_pred_classes.append(np.argmax(y_pred[i][j]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbzl9zXwC7tq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "799ef631-6b83-474c-8c8f-228a52feb99e"
      },
      "source": [
        "print(classification_report(y_pred_classes, np.reshape(data_Y[-1000:], (-1))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.86      0.90       814\n",
            "           1       1.00      1.00      1.00         8\n",
            "           2       0.99      0.98      0.98      3966\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.94      0.94      0.94      1060\n",
            "           5       0.99      0.99      0.99      2097\n",
            "           6       0.92      0.99      0.96       409\n",
            "           7       0.98      0.97      0.98      5720\n",
            "           8       0.92      0.89      0.90       734\n",
            "           9       0.91      0.95      0.93       835\n",
            "          11       0.88      0.97      0.92       165\n",
            "          12       0.96      0.95      0.96      2435\n",
            "          13       0.91      0.92      0.91       734\n",
            "          14       0.85      0.96      0.90       528\n",
            "          15       0.98      0.95      0.96       541\n",
            "          16       0.96      0.96      0.96      2495\n",
            "          17       1.00      1.00      1.00      7458\n",
            "\n",
            "    accuracy                           0.97     30000\n",
            "   macro avg       0.89      0.90      0.89     30000\n",
            "weighted avg       0.97      0.97      0.97     30000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}